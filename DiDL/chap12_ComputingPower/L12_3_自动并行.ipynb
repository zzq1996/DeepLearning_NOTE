{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 12.3. 自动并行\n",
    "\n",
    "深度学习框架（例如，MxNet和PyTorch）会在后端自动构建计算图。**利用计算图，系统可以了解所有依赖关系**，并且可以选择性地并行执行多个不相互依赖的任务以提高速度。例如，12.2节中的图12.2.2独立初始化两个变量。因此，系统可以选择并行执行它们。\n",
    "\n",
    "通常情况下单个操作符将使用所有CPU或单个GPU上的所有计算资源。例如，即使在一台机器上有多个CPU处理器，`dot` 操作符也将使用所有CPU上的所有核心（和线程）。这样的行为同样适用于单个GPU。因此，并行化对于单设备计算机来说并不是很有用，而并行化对于多个设备就很重要了。虽然并行化通常应用在多个GPU之间，但增加本地CPU以后还将提高少许性能。例如，`Hadjis.Zhang.Mitliagkas.ea.2016`则把结合GPU和CPU的训练应用到计算机视觉模型中。借助自动并行化框架的便利性，我们可以依靠几行Python代码实现相同的目标。更广泛地考虑，我们对自动并行计算的讨论主要集中在**使用CPU和GPU的并行计算上，以及计算和通信的并行化内容**。\n",
    "\n",
    "请注意，我们至少需要两个GPU来运行本节中的实验。\n",
    "\n",
    "## 12.3.1. 基于GPU的并行计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [x\u001B[38;5;241m.\u001B[39mmm(x) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m50\u001B[39m)]\n\u001B[1;32m     11\u001B[0m x_gpu1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m4000\u001B[39m, \u001B[38;5;241m4000\u001B[39m), device\u001B[38;5;241m=\u001B[39mdevices[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m---> 12\u001B[0m x_gpu2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m4000\u001B[39m, \u001B[38;5;241m4000\u001B[39m), device\u001B[38;5;241m=\u001B[39mdevices[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m现在我们使用函数来数据。我们通过在测量之前预热设备（对设备执行一次传递）来确保缓存的作用不影响最终的结果。torch.cuda.synchronize()函数将会等待一个CUDA设备上的所有流中的所有核心的计算完成。函数接受一个device参数，代表是哪个设备需要同步。如果device参数是None（默认值），它将使用current_device()找出的当前设备。\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     17\u001B[0m run(x_gpu1)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\"\"\"\n",
    "让我们从定义一个具有参考性的用于测试的工作负载开始：下面的run函数将执行10次“矩阵－矩阵”乘法时需要使用的数据分配到两个变量（x_gpu1和x_gpu2）中，这两个变量分别位于我们选择的不同设备上。\n",
    "\"\"\"\n",
    "devices = d2l.try_all_gpus()\n",
    "def run(x):\n",
    "    return [x.mm(x) for _ in range(50)]\n",
    "\n",
    "x_gpu1 = torch.rand(size=(4000, 4000), device=devices[0])\n",
    "x_gpu2 = torch.rand(size=(4000, 4000), device=devices[1])\n",
    "\n",
    "\"\"\"\n",
    "现在我们使用函数来数据。我们通过在测量之前预热设备（对设备执行一次传递）来确保缓存的作用不影响最终的结果。torch.cuda.synchronize()函数将会等待一个CUDA设备上的所有流中的所有核心的计算完成。函数接受一个device参数，代表是哪个设备需要同步。如果device参数是None（默认值），它将使用current_device()找出的当前设备。\n",
    "\"\"\"\n",
    "run(x_gpu1)\n",
    "run(x_gpu2)  # 预热设备\n",
    "torch.cuda.synchronize(devices[0])\n",
    "torch.cuda.synchronize(devices[1])\n",
    "\n",
    "with d2l.Benchmark('GPU1 time'):\n",
    "    run(x_gpu1)\n",
    "    torch.cuda.synchronize(devices[0])\n",
    "\n",
    "with d2l.Benchmark('GPU2 time'):\n",
    "    run(x_gpu2)\n",
    "    torch.cuda.synchronize(devices[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "如果我们删除两个任务之间的synchronize语句，系统就可以在两个设备上自动实现并行计算。\n",
    "\n",
    "在上述情况下，总执行时间小于两个部分执行时间的总和，因为深度学习框架自动调度两个GPU设备上的计算，而不需要用户编写复杂的代码。\n",
    "\"\"\"\n",
    "with d2l.Benchmark('GPU1 & GPU2'):\n",
    "    run(x_gpu1)\n",
    "    run(x_gpu2)\n",
    "    torch.cuda.synchronize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 12.3.2. 并行计算与通信\n",
    "在许多情况下，我们需要在不同的设备之间移动数据，比如在CPU和GPU之间，或者在不同的GPU之间。例如，当我们打算执行分布式优化时，就需要**移动数据来聚合多个加速卡上的梯度**。让我们通过在GPU上计算，然后将结果复制回CPU来模拟这个过程。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在GPU1上运行: 0.3314 sec\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 3.82 GiB total capacity; 2.72 GiB already allocated; 69.12 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 16\u001B[0m\n\u001B[1;32m     12\u001B[0m x_gpu1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m4000\u001B[39m, \u001B[38;5;241m4000\u001B[39m), device\u001B[38;5;241m=\u001B[39mdevices[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m d2l\u001B[38;5;241m.\u001B[39mBenchmark(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m在GPU1上运行\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 16\u001B[0m     y \u001B[38;5;241m=\u001B[39m run(x_gpu1)\n\u001B[1;32m     17\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39msynchronize()\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m d2l\u001B[38;5;241m.\u001B[39mBenchmark(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m复制到CPU\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "Cell \u001B[0;32mIn [1], line 5\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(x):\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [x\u001B[38;5;241m.\u001B[39mmm(x) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m50\u001B[39m)]\n",
      "Cell \u001B[0;32mIn [1], line 5\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(x):\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m50\u001B[39m)]\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 3.82 GiB total capacity; 2.72 GiB already allocated; 69.12 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def run(x):\n",
    "    return [x.mm(x) for _ in range(50)]\n",
    "\n",
    "def copy_to_cpu(x, non_blocking=False):\n",
    "    return [y.to('cpu', non_blocking=non_blocking) for y in x]\n",
    "\n",
    "devices = d2l.try_all_gpus()\n",
    "\n",
    "x_gpu1 = torch.rand(size=(4000, 4000), device=devices[0])\n",
    "\n",
    "\n",
    "with d2l.Benchmark('在GPU1上运行'):\n",
    "    y = run(x_gpu1)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "with d2l.Benchmark('复制到CPU'):\n",
    "    y_cpu = copy_to_cpu(y)\n",
    "    torch.cuda.synchronize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "两个操作所需的总时间少于它们各部分操作所需时间的总和。请注意，与并行计算的区别是通信操作使用的资源：CPU和GPU之间的总线。事实上，我们可以在两个设备上同时进行计算和通信。如上所述，计算和通信之间存在的依赖关系是必须先计算`y[i]`，然后才能将其复制到CPU。幸运的是，系统可以在计算`y[i]`的同时复制`y[i-1]`，以减少总的运行时间。\n",
    "\n",
    "![avatar](../img/12_4.png)\n",
    "\n",
    "## 12.3.3. 小结\n",
    "- 现代系统拥有多种设备，如多个GPU和多个CPU，还可以并行地、异步地使用它们。\n",
    "- 现代系统还拥有各种通信资源，如PCI Express、存储（通常是固态硬盘或网络存储）和网络带宽，为了达到最高效率可以并行使用它们。\n",
    "- 后端可以通过自动化地并行计算和通信来提高性能。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}