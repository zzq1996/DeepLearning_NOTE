{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4.9 环境和分布偏移\n",
    "有时，根据测试集的精度衡量，模型表现得非常出色。 但是当数据分布突然改变时，模型在部署中会出现灾难性的失败。\n",
    "\n",
    "机器学习的许多应用中都存在类似的问题： 通过将基于模型的决策引入环境，我们可能会破坏模型。\n",
    "\n",
    "## 4.9.1 分布偏移的类型\n",
    "首先，我们考虑数据分布可能发生变化的各种方式，以及为挽救模型性能可能采取的措施。在一个经典的情景中，假设训练数据是从某个分布$p_S(\\mathbf{x},y)$中采样的，但是测试数据将包含从不同分布$p_T(\\mathbf{x},y)$中抽取的未标记样本。一个清醒的现实是：如果没有任何关于$p_S$和$p_T$之间相互关系的假设，学习到一个分类器是不可能的。\n",
    "\n",
    "### 协变量偏移\n",
    "在不同分布偏移中，协变量偏移可能是最为广泛研究的。这里我们假设：虽然输入的分布可能随时间而改变，但标签函数（即条件分布$P(y \\mid \\mathbf{x})$）没有改变。统计学家称之为*协变量偏移*（covariate shift），因为这个问题是由于协变量（特征）分布的变化而产生的。虽然有时我们可以在不引用因果关系的情况下对分布偏移进行推断，但在我们认为$\\mathbf{x}$导致$y$的情况下，协变量偏移是一种自然假设。\n",
    "\n",
    "### 标签偏移\n",
    "**标签偏移**（label shift）描述了与协变量偏移相反的问题。这里我们假设标签边缘概率$P(y)$可以改变，但是类别条件分布$P(\\mathbf{x} \\mid y)$在不同的领域之间保持不变。当我们认为$y$导致$\\mathbf{x}$时，标签偏移是一个合理的假设。例如，预测患者的疾病，我们可能根据症状来判断，即使疾病的相对流行率随着时间的推移而变化。标签偏移在这里是恰当的假设，因为疾病会引起症状。在另一些情况下，标签偏移和协变量偏移假设可以同时成立。例如，当标签是确定的，即使$y$导致$\\mathbf{x}$，协变量偏移假设也会得到满足。有趣的是，在这些情况下，使用基于标签偏移假设的方法通常是有利的。这是因为这些方法倾向于包含看起来像标签（通常是低维）的对象，而不是像输入（通常是高维的）对象。\n",
    "\n",
    "### 概念偏移\n",
    "我们也可能会遇到概念偏移（concept shift）： 当标签的定义发生变化时，就会出现这种问题。\n",
    "\n",
    "如果我们要建立一个机器翻译系统，$P(y \\mid \\mathbf{x})$的分布可能会因我们的位置不同而得到不同的翻译。这个问题可能很难被发现。所以，我们最好可以利用在时间或空间上逐渐发生偏移的知识。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.9.2. 分布偏移示例\n",
    "\n",
    "## 4.9.3. 分布偏移纠正\n",
    "### 经验风险与实际风险\n",
    "\n",
    "首先我们反思一下在模型训练期间到底发生了什么？训练数据$\\{(\\mathbf{x}_1, y_1), \\ldots, (\\mathbf{x}_n, y_n)\\}$的特征和相关的标签经过迭代，在每一个小批量之后更新模型$f$的参数。为了简单起见，我们不考虑正则化，因此极大地降低了训练损失：\n",
    "\n",
    "$$\\mathop{\\mathrm{minimize}}_f \\frac{1}{n} \\sum_{i=1}^n l(f(\\mathbf{x}_i), y_i),$$\n",
    "\n",
    "\n",
    "其中$l$是损失函数，用来度量：给定标签$y_i$，预测$f(\\mathbf{x}_i)$的“糟糕程度”。统计学家称上式为经验风险。*经验风险*（empirical risk）是为了近似 *真实风险*（true risk），整个训练数据上的平均损失，即从其真实分布$p(\\mathbf{x},y)$中抽取的所有数据的总体损失的期望值：\n",
    "\n",
    "$$E_{p(\\mathbf{x}, y)} [l(f(\\mathbf{x}), y)] = \\int\\int l(f(\\mathbf{x}), y) p(\\mathbf{x}, y) \\;d\\mathbf{x}dy.$$\n",
    "\n",
    "\n",
    "然而在实践中，我们通常无法获得总体数据。因此，*经验风险最小化*即在经验风险中最小化经验风险，是一种实用的机器学习策略，希望能近似最小化真实风险。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 协变量偏移纠正\n",
    "假设对于带标签的数据$(\\mathbf{x}_i, y_i)$，我们要评估$P(y \\mid \\mathbf{x})$。然而观测值$\\mathbf{x}_i$是从某些*源分布*$q(\\mathbf{x})$中得出的，而不是从*目标分布*$p(\\mathbf{x})$中得出的。幸运的是，依赖性假设意味着条件分布保持不变，即：$p(y \\mid \\mathbf{x}) = q(y \\mid \\mathbf{x})$。如果源分布$q(\\mathbf{x})$是“错误的”，我们可以通过在真实风险的计算中，使用以下简单的恒等式来进行纠正：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\int\\int l(f(\\mathbf{x}), y) p(y \\mid \\mathbf{x})p(\\mathbf{x}) \\;d\\mathbf{x}dy =\n",
    "\\int\\int l(f(\\mathbf{x}), y) q(y \\mid \\mathbf{x})q(\\mathbf{x})\\frac{p(\\mathbf{x})}{q(\\mathbf{x})} \\;d\\mathbf{x}dy.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "换句话说，我们需要根据数据来自正确分布与来自错误分布的概率之比，来重新衡量每个数据样本的权重：\n",
    "\n",
    "$$\\beta_i \\stackrel{\\mathrm{def}}{=} \\frac{p(\\mathbf{x}_i)}{q(\\mathbf{x}_i)}.$$\n",
    "\n",
    "将权重$\\beta_i$代入到每个数据样本$(\\mathbf{x}_i, y_i)$中，我们可以使用”加权经验风险最小化“来训练模型：\n",
    "\n",
    "$$\\mathop{\\mathrm{minimize}}_f \\frac{1}{n} \\sum_{i=1}^n \\beta_i l(f(\\mathbf{x}_i), y_i).$$\n",
    "\n",
    "\n",
    "由于不知道这个比率，我们需要估计它。有许多方法都可以用，包括一些花哨的算子理论方法，试图直接使用最小范数或最大熵原理重新校准期望算子。对于任意一种这样的方法，我们都需要从两个分布中抽取样本：“真实”的分布$p$，通过访问测试数据获取；训练集$q$，通过人工合成的很容易获得。请注意，我们只需要特征$\\mathbf{x} \\sim p(\\mathbf{x})$，不需要访问标签$y \\sim p(y)$。\n",
    "\n",
    "在这种情况下，有一种非常有效的方法可以得到几乎与原始方法一样好的结果：*对数几率回归*（logistic regression）。这是用于二元分类的softmax回归（见3.4节）的一个特例。综上所述，我们学习了一个分类器来区分从$p(\\mathbf{x})$抽取的数据和从$q(\\mathbf{x})$抽取的数据。如果无法区分这两个分布，则意味着相关的样本可能来自这两个分布中的任何一个。另一方面，任何可以很好区分的样本都应该相应地显著增加或减少权重。\n",
    "\n",
    "为了简单起见，假设我们分别从$p(\\mathbf{x})$和$q(\\mathbf{x})$两个分布中抽取相同数量的样本。现在用$z$标签表示：从$p$抽取的数据为$1$，从$q$抽取的数据为$-1$。然后，混合数据集中的概率由下式给出\n",
    "\n",
    "$$P(z=1 \\mid \\mathbf{x}) = \\frac{p(\\mathbf{x})}{p(\\mathbf{x})+q(\\mathbf{x})} \\text{ and hence } \\frac{P(z=1 \\mid \\mathbf{x})}{P(z=-1 \\mid \\mathbf{x})} = \\frac{p(\\mathbf{x})}{q(\\mathbf{x})}.$$\n",
    "\n",
    "因此，如果我们使用对数几率回归方法，其中$P(z=1 \\mid \\mathbf{x})=\\frac{1}{1+\\exp(-h(\\mathbf{x}))}$（$h$是一个参数化函数），则很自然有：\n",
    "\n",
    "$$\n",
    "\\beta_i = \\frac{1/(1 + \\exp(-h(\\mathbf{x}_i)))}{\\exp(-h(\\mathbf{x}_i))/(1 + \\exp(-h(\\mathbf{x}_i)))} = \\exp(h(\\mathbf{x}_i)).\n",
    "$$\n",
    "\n",
    "因此，我们需要解决两个问题：第一个问题是关于区分来自两个分布的数据；第二个问题是关于加权经验风险的最小化问题。在这个问题中，我们将对其中的项加权$\\beta_i$。\n",
    "\n",
    "现在，我们来看一下完整的协变量偏移纠正算法。假设我们有一个训练集$\\{(\\mathbf{x}_1, y_1), \\ldots, (\\mathbf{x}_n, y_n)\\}$和一个未标记的测试集$\\{\\mathbf{u}_1, \\ldots, \\mathbf{u}_m\\}$。对于协变量偏移，我们假设$1 \\leq i \\leq n$的$\\mathbf{x}_i$来自某个源分布，$\\mathbf{u}_i$来自目标分布。以下是纠正协变量偏移的典型算法：\n",
    "\n",
    "1. 生成一个二元分类训练集：$\\{(\\mathbf{x}_1, -1), \\ldots, (\\mathbf{x}_n, -1), (\\mathbf{u}_1, 1), \\ldots, (\\mathbf{u}_m, 1)\\}$。\n",
    "2. 用对数几率回归训练二元分类器得到函数$h$。\n",
    "3. 使用$\\beta_i = \\exp(h(\\mathbf{x}_i))$或更好的$\\beta_i = \\min(\\exp(h(\\mathbf{x}_i)), c)$（$c$为常量）对训练数据进行加权。\n",
    "4. 使用权重$\\beta_i$进行加权经验风险的最小化问题中$\\{(\\mathbf{x}_1, y_1), \\ldots, (\\mathbf{x}_n, y_n)\\}$的训练。\n",
    "\n",
    "请注意，上述算法依赖于一个重要的假设：需要目标分布(例如，测试分布)中的每个数据样本在训练时出现的概率非零。如果我们找到$p(\\mathbf{x}) > 0$但$q(\\mathbf{x}) = 0$的点，那么相应的重要性权重会是无穷大。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 标签偏移纠正\n",
    "假设我们处理的是$k$个类别的分类任务。使用相同符号，$q$和$p$中分别是源分布（例如训练时的分布）和目标分布（例如测试时的分布）。假设标签的分布随时间变化：$q(y) \\neq p(y)$，但类别条件分布保持不变：$q(\\mathbf{x} \\mid y)=p(\\mathbf{x} \\mid y)$。如果源分布$q(y)$是“错误的”，我们可以根据真实风险中的恒等式进行更正：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\int\\int l(f(\\mathbf{x}), y) p(\\mathbf{x} \\mid y)p(y) \\;d\\mathbf{x}dy =\n",
    "\\int\\int l(f(\\mathbf{x}), y) q(\\mathbf{x} \\mid y)q(y)\\frac{p(y)}{q(y)} \\;d\\mathbf{x}dy.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "这里，重要性权重将对应于标签似然比率\n",
    "\n",
    "$$\\beta_i \\stackrel{\\mathrm{def}}{=} \\frac{p(y_i)}{q(y_i)}.$$\n",
    "\n",
    "标签偏移的一个好处是，如果我们在源分布上有一个相当好的模型，那么我们可以得到对这些权重的一致估计，而不需要处理周边的其他维度。在深度学习中，输入往往是高维对象（如图像），而标签通常是低维（如类别）。\n",
    "\n",
    "为了估计目标标签分布，我们首先采用性能相当好的现成的分类器（通常基于训练数据进行训练），并使用验证集（也来自训练分布）计算其混淆矩阵。混淆矩阵$\\mathbf{C}$是一个$k \\times k$矩阵，其中每列对应于标签类别，每行对应于模型的预测类别。每个单元格的值$c_{ij}$是验证集中，真实标签为$j$，而我们的模型预测为$i$的样本数量所占的比例。\n",
    "\n",
    "现在，我们不能直接计算目标数据上的混淆矩阵，因为我们无法看到真实环境下的样本的标签，除非我们再搭建一个复杂的实时标注流程。然而，我们所能做的是将所有模型在测试时的预测取平均数，得到平均模型输出$\\mu(\\hat{\\mathbf{y}}) \\in \\mathbb{R}^k$，其中第$i$个元素$\\mu(\\hat{y}_i)$是我们模型预测测试集中$i$的总预测分数。\n",
    "\n",
    "结果表明，如果我们的分类器一开始就相当准确，并且目标数据只包含我们以前见过的类别，以及如果标签偏移假设成立（这里最强的假设），我们就可以通过求解一个简单的线性系统来估计测试集的标签分布\n",
    "\n",
    "$$\\mathbf{C} p(\\mathbf{y}) = \\mu(\\hat{\\mathbf{y}}),$$\n",
    "\n",
    "因为作为一个估计，$\\sum_{j=1}^k c_{ij} p(y_j) = \\mu(\\hat{y}_i)$对所有$1 \\leq i \\leq k$成立，其中$p(y_j)$是$k$维标签分布向量$p(\\mathbf{y})$的第$j^\\mathrm{th}$元素。如果我们的分类器一开始就足够精确，那么混淆矩阵$\\mathbf{C}$将是可逆的，进而我们可以得到一个解$p(\\mathbf{y}) = \\mathbf{C}^{-1} \\mu(\\hat{\\mathbf{y}})$。\n",
    "\n",
    "因为我们观测源数据上的标签，所以很容易估计分布$q(y)$。那么对于标签为$y_i$的任何训练样本$i$，我们可以使用我们估计的$p(y_i)/q(y_i)$比率来计算权重$\\beta_i$，并将其代入加权经验风险最小化中。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 概念偏移纠正\n",
    "概念偏移很难用原则性的方式解决。例如，在一个问题突然从“区分猫和狗”偏移为“区分白色和黑色动物”的情况下，除了从零开始收集新标签和训练，别无妙方。幸运的是，在实践中这种极端的偏移是罕见的。相反，通常情况下，概念的变化总是缓慢的。比如下面是一些例子：\n",
    "\n",
    "* 在计算广告中，新产品推出后，旧产品变得不那么受欢迎了。这意味着广告的分布和受欢迎程度是逐渐变化的，任何点击率预测器都需要随之逐渐变化。\n",
    "* 由于环境的磨损，交通摄像头的镜头会逐渐退化，影响摄像头的图像质量。\n",
    "* 新闻内容逐渐变化（即新新闻的出现）。\n",
    "\n",
    "在这种情况下，我们可以使用与训练网络相同的方法，使其适应数据的变化。换言之，我们使用新数据更新现有的网络权重，而不是从头开始训练。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.9.4. 学习问题的分类法\n",
    "### 批量学习\n",
    "\n",
    "在*批量学习*（batch learning）中，我们可以访问一组训练特征和标签$\\{(\\mathbf{x}_1, y_1), \\ldots, (\\mathbf{x}_n, y_n)\\}$，我们使用这些特性和标签训练$f(\\mathbf{x})$。然后，我们部署此模型来对来自同一分布的新数据$(\\mathbf{x}, y)$进行评分。例如，我们可以根据猫和狗的大量图片训练猫检测器。一旦我们训练了它，我们就把它作为智能猫门计算视觉系统的一部分，来控制只允许猫进入。然后这个系统会被安装在客户家中，基本再也不会更新。\n",
    "\n",
    "### 在线学习\n",
    "除了“批量”地学习，我们还可以单个“在线”学习数据$(\\mathbf{x}_i, y_i)$。更具体地说，我们首先观测到$\\mathbf{x}_i$，然后我们得出一个估计值$f(\\mathbf{x}_i)$，只有当我们做到这一点后，我们才观测到$y_i$。然后根据我们的决定，我们会得到奖励或损失。许多实际问题都属于这一类。例如，我们需要预测明天的股票价格，这样我们就可以根据这个预测进行交易。在一天结束时，我们会评估我们的预测是否盈利。换句话说，在*在线学习*（online learning）中，我们有以下的循环。在这个循环中，给定新的观测结果，我们会不断地改进我们的模型。\n",
    "\n",
    "$$\n",
    "\\mathrm{model} ~ f_t \\longrightarrow\n",
    "\\mathrm{data} ~ \\mathbf{x}_t \\longrightarrow\n",
    "\\mathrm{estimate} ~ f_t(\\mathbf{x}_t) \\longrightarrow\n",
    "\\mathrm{observation} ~ y_t \\longrightarrow\n",
    "\\mathrm{loss} ~ l(y_t, f_t(\\mathbf{x}_t)) \\longrightarrow\n",
    "\\mathrm{model} ~ f_{t+1}\n",
    "$$\n",
    "\n",
    "\n",
    "### 老虎机\n",
    "*老虎机*（bandits）是上述问题的一个特例。虽然在大多数学习问题中，我们有一个连续参数化的函数$f$（例如，一个深度网络）。但在一个*老虎机*问题中，我们只有有限数量的手臂可以拉动。也就是说，我们可以采取的行动是有限的。对于这个更简单的问题，可以获得更强的最优性理论保证，这并不令人惊讶。我们之所以列出它，主要是因为这个问题经常被视为一个单独的学习问题的情景。\n",
    "\n",
    "### 控制\n",
    "在很多情况下，环境会记住我们所做的事。不一定是以一种对抗的方式，但它会记住，而且它的反应将取决于之前发生的事情。例如，咖啡锅炉控制器将根据之前是否加热锅炉来观测到不同的温度。在这种情况下，PID（比例—积分—微分）控制器算法是一个流行的选择。同样，一个用户在新闻网站上的行为将取决于之前向她展示的内容（例如，大多数新闻她只阅读一次）。许多这样的算法形成了一个环境模型，在这个模型中，他们的行为使得他们的决策看起来不那么随机。近年来，控制理论（如PID的变体）也被用于自动调整超参数，以获得更好的解构和重建质量，提高生成文本的多样性和生成图像的重建质量\n",
    "\n",
    "### 强化学习\n",
    "*强化学习*（reinforcement learning）强调如何基于环境而行动，以取得最大化的预期利益。国际象棋、围棋、西洋双陆棋或星际争霸都是强化学习的应用实例。再比如，为自动驾驶汽车制造一个控制器，或者以其他方式对自动驾驶汽车的驾驶方式做出反应（例如，试图避开某物体，试图造成事故，或者试图与其合作）。\n",
    "\n",
    "### 考虑到环境\n",
    "上述不同情况之间的一个关键区别是：在静止环境中可能一直有效的相同策略，在环境能够改变的情况下可能不会始终有效。例如，一个交易者发现的套利机会很可能在他开始利用它时就消失了。环境变化的速度和方式在很大程度上决定了我们可以采用的算法类型。例如，如果我们知道事情只会缓慢地变化，就可以迫使任何估计也只能缓慢地发生改变。如果我们知道环境可能会瞬间发生变化，但这种变化非常罕见，我们就可以在使用算法时考虑到这一点。当一个数据科学家试图解决的问题会随着时间的推移而发生变化时，这些类型的知识至关重要。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.9.5. 机器学习中的公平、责任和透明度\n",
    "通常，在建模纠正过程中，模型的预测与训练数据耦合的各种机制都没有得到解释， 研究人员称之为“失控反馈循环”的现象。 此外，我们首先要注意我们是否解决了正确的问题。 比如，预测算法现在在信息传播中起着巨大的中介作用， 个人看到的新闻应该由他们喜欢的Facebook页面决定吗？ 这些只是你在机器学习职业生涯中可能遇到的令人感到“压力山大”的道德困境中的一小部分。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.9.6. 小结\n",
    "- 在许多情况下，训练集和测试集并不来自同一个分布。这就是所谓的分布偏移。\n",
    "- 真实风险是从真实分布中抽取的所有数据的总体损失的预期。然而，这个数据总体通常是无法获得的。经验风险是训练数据的平均损失，用于近似真实风险。在实践中，我们进行经验风险最小化。\n",
    "- 在相应的假设条件下，可以在测试时检测并纠正协变量偏移和标签偏移。在测试时，不考虑这种偏移可能会成为问题。\n",
    "- 在某些情况下，环境可能会记住自动操作并以令人惊讶的方式做出响应。在构建模型时，我们必须考虑到这种可能性，并继续监控实时系统，并对我们的模型和环境以意想不到的方式纠缠在一起的可能性持开放态度。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}