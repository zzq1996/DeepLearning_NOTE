{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 14.14 自然语言推断与数据集\n",
    "在[14.11节](./L14_11_情感分析及数据集.ipynb)中，我们讨论了情感分析问题。这个任务的目的是将单个文本序列分类到预定义的类别中，例如一组情感极性中。然而，当需要决定一个句子是否可以从另一个句子推断出来，或者需要通过识别语义等价的句子来消除句子间冗余时，知道如何对一个文本序列进行分类是不够的。相反，我们需要能够对成对的文本序列进行推断。\n",
    "\n",
    "## 14.14.1 自然语言推断\n",
    "\n",
    "**自然语言推断**（natural language inference）主要研究**假设**（hypothesis）是否可以从**前提**（premise）中推断出来，其中两者都是文本序列。换言之，自然语言推断决定了一对文本序列之间的逻辑关系。这类关系通常分为三种类型：\n",
    "\n",
    "* **蕴涵**（entailment）：假设可以从前提中推断出来。\n",
    "* **矛盾**（contradiction）：假设的否定可以从前提中推断出来。\n",
    "* **中性**（neutral）：所有其他情况。\n",
    "\n",
    "自然语言推断也被称为识别文本蕴涵任务。例如，下面的一个文本对将被贴上“蕴涵”的标签，因为假设中的“表白”可以从前提中的“拥抱”中推断出来。\n",
    "\n",
    ">前提：两个女人拥抱在一起。\n",
    "\n",
    ">假设：两个女人在示爱。\n",
    "\n",
    "下面是一个“矛盾”的例子，因为“运行编码示例”表示“不睡觉”，而不是“睡觉”。\n",
    "\n",
    ">前提：一名男子正在运行Dive Into Deep Learning的编码示例。\n",
    "\n",
    ">假设：该男子正在睡觉。\n",
    "\n",
    "第三个例子显示了一种“中性”关系，因为“正在为我们表演”这一事实无法推断出“出名”或“不出名”。\n",
    "\n",
    ">前提：音乐家们正在为我们表演。\n",
    "\n",
    ">假设：音乐家很有名。\n",
    "\n",
    "自然语言推断一直是理解自然语言的中心话题。它有着广泛的应用，从信息检索到开放领域的问答。为了研究这个问题，我们将首先研究一个流行的自然语言推断基准数据集。\n",
    "\n",
    "## 14.14.2 斯坦福自然语言推断（SNLI）数据集\n",
    "\n",
    "[**斯坦福自然语言推断语料库（Stanford Natural Language Inference，SNLI）**]是由500000多个带标签的英语句子对组成的集合`Bowman.Angeli.Potts.ea.2015`。我们在路径`../data/snli_1.0`中下载并存储提取的SNLI数据集。\n",
    "\n",
    "\n",
    "### 读取数据集\n",
    "原始的SNLI数据集包含的信息比我们在实验中真正需要的信息丰富得多。因此，我们定义函数read_snli以仅提取数据集的一部分，然后返回前提、假设及其标签的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前提： A person on a horse jumps over a broken down airplane . \n",
      "假设： A person is training his horse for a competition . \n",
      "标签： 2\n",
      "前提： A person on a horse jumps over a broken down airplane . \n",
      "假设： A person is at a diner , ordering an omelette . \n",
      "标签： 1\n",
      "前提： A person on a horse jumps over a broken down airplane . \n",
      "假设： A person is outdoors , on a horse . \n",
      "标签： 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\"\"\"\n",
    "下载数据集\n",
    "\"\"\"\n",
    "#@save\n",
    "d2l.DATA_HUB['SNLI']=('https://nlp.stanford.edu/projects/snli/snli_1.0.zip','9fcde07509c7e87ec61c640c1b2753d9041758e4')\n",
    "\n",
    "data_dir=d2l.download_extract('SNLI')\n",
    "\n",
    "\"\"\"\n",
    "读取数据集\n",
    "\"\"\"\n",
    "#@save\n",
    "def read_snli(data_dir,is_train):\n",
    "    \"\"\"将SNLI数据集解析为前提、假设和标签\"\"\"\n",
    "    def extract_text(s):\n",
    "        # 删除我们不会使用的信息\n",
    "        s=re.sub('\\\\(','',s)\n",
    "        s=re.sub('\\\\)','',s)\n",
    "        # 用一个空格替换两个或多个连续的空格\n",
    "        s=re.sub('\\\\s{2,}',' ',s)\n",
    "        return s.strip()\n",
    "\n",
    "    label_set={'entailment':0,'contradiction':1,'neutral':2}\n",
    "    file_name=os.path.join(data_dir,'snli_1.0_train.txt' if is_train else 'snli_1.0_test.txt')\n",
    "\n",
    "    with open(file_name,'r') as f:\n",
    "        rows=[row.split('\\t') for row in f.readlines()[1:]]\n",
    "\n",
    "    premises=[extract_text(row[1]) for row in rows if row[0] in label_set]\n",
    "\n",
    "    hypotheses=[extract_text(row[2]) for row in rows if row[0] in label_set]\n",
    "\n",
    "    labels=[label_set[row[0]] for row in rows if row[0] in label_set]\n",
    "\n",
    "    return premises,hypotheses,labels\n",
    "\n",
    "\"\"\"\n",
    "现在让我们打印前3对前提和假设，以及它们的标签（“0”、“1”和“2”分别对应于“蕴涵”、“矛盾”和“中性”）。\n",
    "\"\"\"\n",
    "train_data=read_snli(data_dir,is_train=True)\n",
    "for x0,x1,y in zip(train_data[0][:3],train_data[1][:3],train_data[2][:3]):\n",
    "    print('前提：',x0,'\\n假设：',x1,'\\n标签：',y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183416, 183187, 182764]\n",
      "[3368, 3237, 3219]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "训练集约有550000对，测试集约有10000对。\n",
    "\n",
    "下面显示了训练集和测试集中的三个标签“蕴涵”、“矛盾”和“中性”是平衡的。\n",
    "\"\"\"\n",
    "test_data=read_snli(data_dir,is_train=False)\n",
    "for data in [train_data,test_data]:\n",
    "    print([[row for row in data[2]].count(i) for i in range(3)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义用于加载数据集的类"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "下面我们来定义一个用于加载SNLI数据集的类。\n",
    "\n",
    "类构造函数中的变量num_steps指定文本序列的长度，使得每个小批量序列将具有相同的形状。\n",
    "\n",
    "换句话说，在较长序列中的前num_steps个标记之后的标记被截断，而特殊标记“<pad>”将被附加到较短的序列后，直到它们的长度变为num_steps。\n",
    "\n",
    "通过实现__getitem__功能，我们可以任意访问带有索引idx的前提、假设和标签。\n",
    "\"\"\"\n",
    "#@save\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"用于加载SNLI数据集的自定义数据集\"\"\"\n",
    "    def __init__(self,dataset,num_steps,vocab=None):\n",
    "        self.num_steps=num_steps\n",
    "        all_premise_tokens=d2l.tokenize(dataset[0])\n",
    "        all_hypothesis_tokens=d2l.tokenize(dataset[1])\n",
    "\n",
    "        if vocab is None:\n",
    "            self.vocab=d2l.Vocab(all_premise_tokens+all_hypothesis_tokens,min_freq=5,reserved_tokens=['<pad>'])\n",
    "        else:\n",
    "            self.vocab=vocab\n",
    "\n",
    "        self.premises=self._pad(all_premise_tokens)\n",
    "        self.hypotheses=self._pad(all_hypothesis_tokens)\n",
    "        self.labels=torch.tensor(dataset[2])\n",
    "        print('read'+str(len(self.premises))+' examples')\n",
    "\n",
    "    def _pad(self,lines):\n",
    "        return torch.tensor([d2l.truncate_pad(self.vocab[line],self.num_steps,self.vocab['<pad>']) for line in lines])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.premises[idx],self.hypotheses[idx]),self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.premises)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 整合代码"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read549367 examples\n",
      "read9824 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": "18678"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "现在，我们可以调用read_snli函数和SNLIDataset类来下载SNLI数据集，并返回训练集和测试集的DataLoader实例，以及训练集的词表。\n",
    "\n",
    "值得注意的是，我们必须使用从训练集构造的词表作为测试集的词表。\n",
    "\n",
    "因此，在训练集中训练的模型将不知道来自测试集的任何新词元。\n",
    "\"\"\"\n",
    "#@save\n",
    "def load_data_snli(batch_size,num_steps=50):\n",
    "    \"\"\"下载SNLI数据集并返回数据迭代器和词表\"\"\"\n",
    "    num_workers=d2l.get_dataloader_workers()\n",
    "    data_dir=d2l.download_extract('SNLI')\n",
    "    train_data=read_snli(data_dir,True)\n",
    "    test_data=read_snli(data_dir,False)\n",
    "\n",
    "    train_set=SNLIDataset(train_data,num_steps)\n",
    "    test_set=SNLIDataset(test_data,num_steps,train_set.vocab)\n",
    "\n",
    "    train_iter=torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    test_iter=torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_iter,test_iter,train_set.vocab\n",
    "\n",
    "\"\"\"\n",
    "在这里，我们将批量大小设置为128时，将序列长度设置为50，并调用load_data_snli函数来获取数据迭代器和词表。然后我们打印词表大小。\n",
    "\"\"\"\n",
    "train_iter,test_iter,vocab=load_data_snli(128,50)\n",
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 50]) torch.Size([128, 50]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "现在我们打印第一个小批量的形状。\n",
    "与情感分析相反，我们有分别代表前提和假设的两个输入X[0]和X[1]。\n",
    "\"\"\"\n",
    "for X,Y in train_iter:\n",
    "    print(X[0].shape,X[1].shape,Y.shape)\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 15.4.3. 小结\n",
    "- 自然语言推断研究“假设”是否可以从“前提”推断出来，其中两者都是文本序列。\n",
    "- 在自然语言推断中，前提和假设之间的关系包括蕴涵关系、矛盾关系和中性关系。\n",
    "- 斯坦福自然语言推断（SNLI）语料库是一个比较流行的自然语言推断基准数据集。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}