{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5.3. 延后初始化\n",
    "到目前为止，我们忽略了建立网络时需要做的以下这些事情：\n",
    "- 我们定义了网络架构，但没有指定输入维度。\n",
    "- 我们添加层时没有指定前一层的输出维度。\n",
    "- 我们在初始化参数时，甚至没有足够的信息来确定模型应该包含多少参数。\n",
    "\n",
    "你可能会对我们的代码能运行感到惊讶。毕竟，深度学习框架无法判断网络的输入维度是什么。这里的诀窍是框架的延后初始化（defers initialization），即直到数据第一次通过模型传递时，框架才会动态地推断出每个层的大小。\n",
    "\n",
    "在以后，当使用卷积神经网络时，由于输入维度（即图像的分辨率）将影响每个后续层的维数，有了该技术将更加方便。现在我们在编写代码时无须知道维度是什么就可以设置参数，这种能力可以大大简化定义和修改模型的任务。 接下来，我们将更深入地研究初始化机制。\n",
    "\n",
    "## 5.3.1. 实例化网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UninitializedParameter> Sequential(\n",
      "  (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.1706,  0.0072, -0.1139,  ..., -0.0669, -0.0486,  0.0967],\n",
      "        [-0.2068, -0.2039, -0.1357,  ...,  0.2235, -0.0653,  0.2234],\n",
      "        [ 0.0508, -0.1014,  0.0979,  ..., -0.0230, -0.1201, -0.0487],\n",
      "        ...,\n",
      "        [-0.1803,  0.0215,  0.0798,  ...,  0.1120,  0.1920,  0.0732],\n",
      "        [-0.0224,  0.1880, -0.1975,  ...,  0.1959,  0.0158, -0.1211],\n",
      "        [ 0.0876,  0.1240,  0.1797,  ...,  0.1431, -0.2216, -0.0829]],\n",
      "       requires_grad=True) Sequential(\n",
      "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\"\"\"\n",
    "使用 torch.nn.LazyLinear，但是PyTorch的这个功能正处于开发阶段，API或功能的变化随时可能发生。\n",
    "延后初始化\n",
    "\"\"\"\n",
    "net = nn.Sequential(nn.LazyLinear(256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.LazyLinear(10))\n",
    "print(net[0].weight, net)  # 尚未初始化\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)\n",
    "print(net[0].weight, net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3.2. 小结\n",
    "- 延后初始化使框架能够自动推断参数形状，使修改模型架构变得容易，避免了一些常见的错误。\n",
    "- 我们可以通过模型传递数据，使框架最终初始化参数。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}