{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 神经网络训练和推理流程概览\n",
        "\n",
        "本Notebook使用机器学习入门经典数据集Iris来演示神经网络的训练和推理（测试）流程。\n",
        "\n",
        "Iris是鸢尾花分类数据集，其中每一条数据包含花萼长度、花萼宽度、花瓣长度、花瓣宽度、以及花的品种，如下所示："
      ],
      "metadata": {
        "id": "aguuBRrtHR8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()  # 加载iris数据集\n",
        "X_data = pd.DataFrame(iris.data, columns=iris.feature_names)  # iris.data是输入\n",
        "y_data = pd.DataFrame(iris.target, columns=['target'])  # iris.target是标签\n",
        "data = pd.concat([X_data, y_data], axis=1)\n",
        "data_train, data_test = train_test_split(data, test_size=0.1, random_state=42)  # 划分训练集和测试集"
      ],
      "metadata": {
        "id": "rYD6_G6hIOPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "P8nJGi6lITGO",
        "outputId": "a1262302-44dc-4fa0-cb1e-23e26f40c9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                  5.1               3.5                1.4               0.2   \n",
              "1                  4.9               3.0                1.4               0.2   \n",
              "2                  4.7               3.2                1.3               0.2   \n",
              "3                  4.6               3.1                1.5               0.2   \n",
              "4                  5.0               3.6                1.4               0.2   \n",
              "..                 ...               ...                ...               ...   \n",
              "145                6.7               3.0                5.2               2.3   \n",
              "146                6.3               2.5                5.0               1.9   \n",
              "147                6.5               3.0                5.2               2.0   \n",
              "148                6.2               3.4                5.4               2.3   \n",
              "149                5.9               3.0                5.1               1.8   \n",
              "\n",
              "     target  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "..      ...  \n",
              "145       2  \n",
              "146       2  \n",
              "147       2  \n",
              "148       2  \n",
              "149       2  \n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d908fc14-5e06-45e6-93e7-7a8a8d0af296\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d908fc14-5e06-45e6-93e7-7a8a8d0af296')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d908fc14-5e06-45e6-93e7-7a8a8d0af296 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d908fc14-5e06-45e6-93e7-7a8a8d0af296');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1801af66-780b-4d10-8cc7-0e550ec3e865\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1801af66-780b-4d10-8cc7-0e550ec3e865')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1801af66-780b-4d10-8cc7-0e550ec3e865 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们将花萼长度、花萼宽度、花瓣长度、花瓣宽度分别记为$x_1,x_2,x_3,x_4$，花的品种记为$y$\n",
        "\n",
        "我们的目标是找到一个函数$f$，可以输入$x_1,x_2,x_3,x_4$，输出花的品种$y$.\n",
        "\n",
        "我们可以将函数$f$构造为最简单的线性函数$f(x_1,x_2,x_3,x_4)=w_1x_1+w_2x_2+w_3x_3+w_4x_4+b$，其中$w_1,w_2,w_3,w_4$都是需要学习的参数：\n"
      ],
      "metadata": {
        "id": "Sj-uIgWPJxpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 直观的函数定义"
      ],
      "metadata": {
        "id": "t1Au5lPLPzsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class F1(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 将函数的参数定义在__init__方法中\n",
        "    self.w1 = nn.Parameter(torch.tensor(0.1))\n",
        "    self.w2 = nn.Parameter(torch.tensor(0.2))\n",
        "    self.w3 = nn.Parameter(torch.tensor(0.3))\n",
        "    self.w4 = nn.Parameter(torch.tensor(0.4))\n",
        "    self.b = nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "  def forward(self, x1, x2, x3, x4):\n",
        "    # 将函数的调用过程定义在forward方法中\n",
        "    return (\n",
        "      self.w1*x1+\n",
        "      self.w2*x2+\n",
        "      self.w3*x3+\n",
        "      self.w4*x4+\n",
        "      self.b\n",
        "    )\n",
        "\n",
        "\n",
        "# 初始化函数\n",
        "f1 = F1()\n",
        "# 调用函数（把第一条数据代入函数计算）\n",
        "y_pred = f1(torch.tensor(5.1), torch.tensor(3.5), torch.tensor(1.4), torch.tensor(0.2))\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QSeelx8IT6Y",
        "outputId": "cbe1b6b0-1aa6-45c1-ca02-2aa9876ba85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7100, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到，在上面的代码中，我们将$f$的参数$w_1,w_2,w_3,w_4,b$分别初始化为$0.1,0.2,0.3,0.4,0.0$（也可以随机初始化），将第一组数据$(5.1,3.5,1.4,0.2)$代入$f$计算得到$f(5.1,3.5,1.4,0.2)=1.71$。\n",
        "\n",
        "## 2. 向量化\n",
        "\n",
        "上面的代码太过冗余，5个参数定义了5次，并且调用时需要传入4个tensor，我们可以把参数和函数的输入向量化："
      ],
      "metadata": {
        "id": "7oyGrlfNOTOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class F2(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.w = nn.Parameter(torch.tensor([0.1,0.2,0.3,0.4]))\n",
        "    self.b = nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # 用向量(w1,w2,w3,w4)点乘向量(x1,x2,x3,x4)，再加上b，与原始表达式等价\n",
        "    return self.w.dot(x) + self.b\n",
        "\n",
        "\n",
        "# 初始化函数\n",
        "f2 = F2()\n",
        "# 调用函数（把第一条数据代入函数计算）\n",
        "y = f2(torch.tensor([5.1, 3.5, 1.4, 0.2]))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kkfteOvOCd0",
        "outputId": "bab3058e-a349-4864-fa73-8997e50405f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7100, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "向量化后，$w_1,w_2,w_3,w_4$四个参数被定义在了一个向量中，$x_1,x_2,x_3,x_4$四个输入也被包含在了一个向量中，代码简洁了很多。\n",
        "\n",
        "## 3. 批量化\n",
        "\n",
        "上述函数每次只允许我们输入一条数据，没有办法攒多条数据一起丢给函数让它并行地算出结果来。\n",
        "\n",
        "在上述函数中，我们已经把参数$w$看作了一个向量：$\\mathbf{w}=\\left[\\begin{aligned}w_1\\\\w_2\\\\w_3\\\\w_4\\end{aligned}\\right]$\n",
        "\n",
        "也把每条数据看成了一个向量：$\\mathbf{x}^{(i)}=\\left[\\begin{aligned}x_1^{(i)}\\\\x_2^{(i)}\\\\x_3^{(i)}\\\\x_4^{(i)}\\end{aligned}\\right]$，其中上标$(i)$表示第$i$条数据\n",
        "\n",
        "计算过程也变为了参数向量与数据向量的点乘：$f(\\mathbf{x}^{(i)})=\\mathbf{w}^T\\mathbf{x}^{(i)}=w_1x_1^{(i)}+w_2x_2^{(i)}+w_3x_3^{(i)}+w_4x_4^{(i)}$\n",
        "\n",
        "现在，我们把3条数据攒成一个batch，并看作一个矩阵：$\n",
        "X^{(i:i+2)}=\\left[\n",
        "\\begin{aligned}\n",
        "x_1^{(i)}~x_1^{(i+1)}~x_1^{(i+2)}\\\\\n",
        "x_2^{(i)}~x_2^{(i+1)}~x_2^{(i+2)}\\\\\n",
        "x_3^{(i)}~x_3^{(i+1)}~x_3^{(i+2)}\\\\\n",
        "x_4^{(i)}~x_4^{(i+1)}~x_4^{(i+2)}\n",
        "\\end{aligned}\\right]\n",
        "$\n",
        "\n",
        "此时，仍然使用参数向量的转置$\\mathbf{w}^T$乘上这个矩阵，我们就能得到一个向量，这个向量包含每条数据的函数值：\n",
        "\n",
        "$$\n",
        "\\mathbf{w}^TX^{(i:i+2)}=[w_1,w_2,w_3,w_4]\\cdot\\left[\n",
        "\\begin{aligned}\n",
        "x_1^{(i)}~x_1^{(i+1)}~x_1^{(i+2)}\\\\\n",
        "x_2^{(i)}~x_2^{(i+1)}~x_2^{(i+2)}\\\\\n",
        "x_3^{(i)}~x_3^{(i+1)}~x_3^{(i+2)}\\\\\n",
        "x_4^{(i)}~x_4^{(i+1)}~x_4^{(i+2)}\n",
        "\\end{aligned}\\right]=[f(\\mathbf{x}^{(i)}),f(\\mathbf{x}^{(i+1)}),f(\\mathbf{x}^{(i+2)})]\n",
        "$$\n",
        "\n",
        "如此一来，3条数据的函数值通过矩阵乘法被并行地计算了出来。\n",
        "\n",
        "代码实现如下："
      ],
      "metadata": {
        "id": "Cg2oWTkUQ2YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class F3(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.w = nn.Parameter(torch.tensor([[0.1,0.2,0.3,0.4]]))  # 多加一层括号就从4维向量变成了1x4的矩阵，然后就可以跟矩阵相乘了\n",
        "    self.b = nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.w @ x.T + self.b  # 这里的实现是w乘上x的转置，和公式里相反，因为代码里w是行向量，x中的每个xi也是行向量\n",
        "\n",
        "\n",
        "# 初始化函数\n",
        "f3 = F3()\n",
        "# 调用函数（把前2条数据攒成batch代入函数计算）\n",
        "y = f3(\n",
        "  torch.tensor([\n",
        "    [5.1, 3.5, 1.4, 0.2],\n",
        "    [4.9, 3.0, 1.4, 0.2],\n",
        "  ])\n",
        ")\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHLMV1ijQKD3",
        "outputId": "78f9a043-20a4-4bd2-c8fa-78df06c8689c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.7100, 1.5900], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 计算损失\n",
        "\n",
        "我们需要定义一个损失函数来评量函数$f$的好坏，损失函数越小说明函数$f$越好。\n",
        "\n",
        "我们将损失函数定义为函数$f$在整个数据集$\\mathcal{D}$上的预测值与真实值的均方误差：\n",
        "\n",
        "$$\n",
        "L(f)=\\frac{1}{|\\mathcal{D}|}\\sum_{(\\mathbf{x},y)\\in\\mathcal{D}}(f(\\mathbf{x})-y)^2\n",
        "$$\n",
        "\n",
        "代码实现为："
      ],
      "metadata": {
        "id": "p6z0symXb4G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_pred, y):\n",
        "  return ((y_pred - y)**2).mean()"
      ],
      "metadata": {
        "id": "9__wriaATzre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们需要遍历每一条数据$\\mathbf{x}^{(i)},y^{(i)}$，通过函数$f$计算预测值$f(\\mathbf{x}^{(i)})$，并计算预测值与真实值$y^{(i)}$之间的均方误差，最后加起来可以得到损失函数的值。\n",
        "\n",
        "为了加快速度，我们将`batch_size`设为4，攒4条数据一起丢给函数进行预测："
      ],
      "metadata": {
        "id": "-FH0VzN2eXLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "f = F3()\n",
        "loss_list = []\n",
        "for i in range(0, len(data_train), 4):  # 只在训练集上计算\n",
        "  x = torch.tensor(np.array(data_train.iloc[i:i+4, :-1]), dtype=torch.float32)\n",
        "  y = torch.tensor(np.array(data_train.iloc[i:i+4, -1]), dtype=torch.float32)\n",
        "  y_pred = f(x)\n",
        "  loss = loss_function(y_pred, y)\n",
        "  loss_list.append(loss)\n",
        "total_loss = sum(loss_list)\n",
        "print(\"Total loss:\", total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRt2Sr8Cdy5T",
        "outputId": "79d6ded2-c9e7-4c95-ce3a-8621df884986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss: tensor(112.3935, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 反向传播\n",
        "\n",
        "上面我们计算出了函数$f$在当前的参数下，在整个Iris数据集上的损失。\n",
        "\n",
        "接下来我们要使用AdamW优化器对函数$f$的参数进行更新，使损失可以减小一点："
      ],
      "metadata": {
        "id": "rwi8meAWhMxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(\n",
        "    params=f.parameters(),  # 需要优化的参数\n",
        "    lr=0.1,  # 学习率，即参数更新的步伐大小\n",
        ")"
      ],
      "metadata": {
        "id": "57OOLwltgHYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到，优化器中已经载入了$f$中定义的参数$\\mathbf{w}=[0.1,0.2,0.3,0.4]^T$以及$b=0.0$："
      ],
      "metadata": {
        "id": "JmQAZlWYiXCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.param_groups[0][\"params\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riTGo54jh1ob",
        "outputId": "199bf445-d645-4d70-8dc8-8e2b5bb85906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.1000, 0.2000, 0.3000, 0.4000]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor(0., requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "接下来，我们调用`total_loss`的`backward`方法。这一做法会让pytorch在后端计算出`total_loss`关于参数`w`和参数`b`的梯度，即$\\nabla_{\\mathbf{w}}L(f)=\\frac{\\partial L(f)}{\\partial \\mathbf{w}}$和$\\nabla_{b}L(f)=\\frac{\\partial L(f)}{\\partial b}$。"
      ],
      "metadata": {
        "id": "CB-riGl-ifvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss.backward()"
      ],
      "metadata": {
        "id": "hiK50EGriOIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$L$关于$\\mathbf{w}$的梯度$\\nabla_{\\mathbf{w}}L(f)$是一个形状与参数$\\mathbf{w}$相同的向量，它表示一个方向，当$\\mathbf{w}$沿此方向改变时，对$L$的改变最大。\n",
        "\n",
        "$\\nabla_{b}L(f)$同理。\n",
        "\n",
        "通过调用`optimizer.step()`可以使`optimizer`中载入的参数沿梯度所指的方向更新参数，从而使$L$变小："
      ],
      "metadata": {
        "id": "CX4AGR6rlSBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "PlmpbOIxjs0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以看看，函数$f$的参数现在变成什么样子了："
      ],
      "metadata": {
        "id": "Tvwdtn1nlt9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f.w)\n",
        "print(f.b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KHM57CfjvyV",
        "outputId": "d813b9ba-10d6-4d5a-b706-3e08f84ea3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.0000e-04,  9.9800e-02,  1.9970e-01,  2.9960e-01]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor(-0.1000, requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以看到，`w`中每个值都减小了$0.01$，`b`也减小了0.01，这可以反推出`total_loss.backward()`中计算出的梯度为$\\nabla_{\\mathbf{w}}L(f)\\approx[0.01,0.01,0.01,0.01]^T$，以及$\\nabla_{\\mathbf{w}}L(f)\\approx 0.01$\n",
        "\n",
        "再次计算loss可以发现，loss比之前确实减小了："
      ],
      "metadata": {
        "id": "3TvJMnidl1k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "for i in range(0, len(data_train), 4):\n",
        "  x = torch.tensor(np.array(data_train.iloc[i:i+4, :-1]), dtype=torch.float32)\n",
        "  y = torch.tensor(np.array(data_train.iloc[i:i+4, -1]), dtype=torch.float32)\n",
        "  y_pred = f(x)\n",
        "  loss = loss_function(y_pred, y)\n",
        "  loss_list.append(loss)\n",
        "total_loss = sum(loss_list)\n",
        "print(\"Total loss:\", total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdXEImkdl0IF",
        "outputId": "c19c9fa1-da83-4ac5-ae52-50bb7f12867d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss: tensor(6.8916, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "重复上述过程，对数据集遍历100个`epoch`，并观察loss如何变化："
      ],
      "metadata": {
        "id": "2-DPr0Simqvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for i_epoch in range(num_epochs):\n",
        "  # 前向传播\n",
        "  loss_list = []\n",
        "  for i in range(0, len(data_train), 4):\n",
        "    x = torch.tensor(np.array(data_train.iloc[i:i+4, :-1]), dtype=torch.float32)\n",
        "    y = torch.tensor(np.array(data_train.iloc[i:i+4, -1]), dtype=torch.float32)\n",
        "    y_pred = f(x)\n",
        "    loss = loss_function(y_pred, y)\n",
        "    loss_list.append(loss)\n",
        "  total_loss = sum(loss_list)\n",
        "  print(\"Total loss:\", total_loss.item())\n",
        "\n",
        "  # 反向传播\n",
        "  optimizer.zero_grad()  # 每次backward之前要先清空上次累积在后台的梯度\n",
        "  total_loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNhv5n0Emm7V",
        "outputId": "36becb9e-ef63-4858-8bf0-905ed41e192d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss: 6.891600608825684\n",
            "Total loss: 33.027713775634766\n",
            "Total loss: 59.78230667114258\n",
            "Total loss: 41.90623092651367\n",
            "Total loss: 13.976655006408691\n",
            "Total loss: 3.4685986042022705\n",
            "Total loss: 13.15591049194336\n",
            "Total loss: 26.092050552368164\n",
            "Total loss: 27.26593780517578\n",
            "Total loss: 17.30009651184082\n",
            "Total loss: 6.126542568206787\n",
            "Total loss: 2.2355329990386963\n",
            "Total loss: 6.526439189910889\n",
            "Total loss: 12.894046783447266\n",
            "Total loss: 14.734004974365234\n",
            "Total loss: 10.780180931091309\n",
            "Total loss: 4.886590480804443\n",
            "Total loss: 1.774026870727539\n",
            "Total loss: 3.096604585647583\n",
            "Total loss: 6.549545764923096\n",
            "Total loss: 8.431142807006836\n",
            "Total loss: 7.095152854919434\n",
            "Total loss: 3.9898970127105713\n",
            "Total loss: 1.8500605821609497\n",
            "Total loss: 2.1487560272216797\n",
            "Total loss: 4.006176471710205\n",
            "Total loss: 5.311361789703369\n",
            "Total loss: 4.818202972412109\n",
            "Total loss: 3.1321418285369873\n",
            "Total loss: 1.8517488241195679\n",
            "Total loss: 1.9548126459121704\n",
            "Total loss: 2.9883344173431396\n",
            "Total loss: 3.705125570297241\n",
            "Total loss: 3.373322010040283\n",
            "Total loss: 2.3967180252075195\n",
            "Total loss: 1.743348479270935\n",
            "Total loss: 1.916345477104187\n",
            "Total loss: 2.5286192893981934\n",
            "Total loss: 2.8226394653320312\n",
            "Total loss: 2.4909751415252686\n",
            "Total loss: 1.9173005819320679\n",
            "Total loss: 1.6747640371322632\n",
            "Total loss: 1.905189871788025\n",
            "Total loss: 2.2378437519073486\n",
            "Total loss: 2.2603352069854736\n",
            "Total loss: 1.9642736911773682\n",
            "Total loss: 1.6895813941955566\n",
            "Total loss: 1.7009178400039673\n",
            "Total loss: 1.909911870956421\n",
            "Total loss: 2.0275237560272217\n",
            "Total loss: 1.916914701461792\n",
            "Total loss: 1.722097635269165\n",
            "Total loss: 1.6599111557006836\n",
            "Total loss: 1.7613976001739502\n",
            "Total loss: 1.8660069704055786\n",
            "Total loss: 1.838484287261963\n",
            "Total loss: 1.7225536108016968\n",
            "Total loss: 1.660049319267273\n",
            "Total loss: 1.7064728736877441\n",
            "Total loss: 1.778367042541504\n",
            "Total loss: 1.7761383056640625\n",
            "Total loss: 1.7072809934616089\n",
            "Total loss: 1.6595885753631592\n",
            "Total loss: 1.680120587348938\n",
            "Total loss: 1.7238634824752808\n",
            "Total loss: 1.725274682044983\n",
            "Total loss: 1.6840649843215942\n",
            "Total loss: 1.6546483039855957\n",
            "Total loss: 1.6676326990127563\n",
            "Total loss: 1.6943978071212769\n",
            "Total loss: 1.693725824356079\n",
            "Total loss: 1.667303204536438\n",
            "Total loss: 1.6503187417984009\n",
            "Total loss: 1.659695029258728\n",
            "Total loss: 1.6749314069747925\n",
            "Total loss: 1.6717842817306519\n",
            "Total loss: 1.6553510427474976\n",
            "Total loss: 1.6481598615646362\n",
            "Total loss: 1.6565802097320557\n",
            "Total loss: 1.6647453308105469\n",
            "Total loss: 1.6599446535110474\n",
            "Total loss: 1.6495341062545776\n",
            "Total loss: 1.647347092628479\n",
            "Total loss: 1.6534063816070557\n",
            "Total loss: 1.6563478708267212\n",
            "Total loss: 1.651416540145874\n",
            "Total loss: 1.6460515260696411\n",
            "Total loss: 1.6471467018127441\n",
            "Total loss: 1.6512031555175781\n",
            "Total loss: 1.6510696411132812\n",
            "Total loss: 1.646859884262085\n",
            "Total loss: 1.6445398330688477\n",
            "Total loss: 1.6462674140930176\n",
            "Total loss: 1.6479567289352417\n",
            "Total loss: 1.646429419517517\n",
            "Total loss: 1.643965482711792\n",
            "Total loss: 1.6439334154129028\n",
            "Total loss: 1.645510196685791\n",
            "Total loss: 1.6455904245376587\n",
            "Total loss: 1.64383065700531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "观察到，loss降到1.64左右时没法再下降了。\n",
        "\n",
        "这说明，在当前的超参数配置下，函数/模型$f$在Iris数据集上的训练已经收敛。\n",
        "\n",
        "我们看看收敛后的参数："
      ],
      "metadata": {
        "id": "pukqgXmKnq1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f.w)\n",
        "print(f.b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkG9QjxjnPfd",
        "outputId": "9509c880-d435-4977-9cbf-cbeb004b6498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0547, -0.0366,  0.2676,  0.4737]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor(-0.1373, requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 模型测试\n",
        "\n",
        "接下来我们对训练好的模型$f$在测试集上进行测试，评估$f$在测试集上的loss:"
      ],
      "metadata": {
        "id": "7l84w8UmqT-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 前向传播\n",
        "loss_list = []\n",
        "y_preds = []\n",
        "y_trues = []\n",
        "for i in range(0, len(data_test), 4):\n",
        "  x = torch.tensor(np.array(data_test.iloc[i:i+4, :-1]), dtype=torch.float32)\n",
        "  y = torch.tensor(np.array(data_test.iloc[i:i+4, -1]), dtype=torch.float32)\n",
        "  y_pred = f(x)\n",
        "  y_preds.extend(y_pred.squeeze().tolist())\n",
        "  y_trues.extend(y.squeeze().tolist())\n",
        "  loss = loss_function(y_pred, y)\n",
        "  loss_list.append(loss)\n",
        "avg_loss = sum(loss_list)\n",
        "print(\"Average loss:\", avg_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vSLXeG7oCmN",
        "outputId": "6933a00c-aef6-498a-f9ec-33d61ede4d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: tensor(0.1654, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "另外还需计算$f$在测试集上的准确率。这里我们的预测值是连续值，但是真实值，我们直接取其四舍五入的整数值作为最终的分类预测："
      ],
      "metadata": {
        "id": "BVI7fbMarVVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = [round(y_pred) for y_pred in y_preds]"
      ],
      "metadata": {
        "id": "3Y8gn_i4qrO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDm_bneGUbRM",
        "outputId": "37ac0c65-42d3-442d-8268-0f28e1f2bb37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "准确率轻松地达到了100%："
      ],
      "metadata": {
        "id": "bcncrM_0r5nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (np.array(y_preds) == np.array(y_trues)).mean()\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32nXl-n8rKgK",
        "outputId": "71380462-ce18-4b13-dfd8-91d20b4f1d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_preds) == np.array(y_trues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVoqeTKLUw_v",
        "outputId": "13572a76-031a-40a6-af62-8c346427c291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 让函数输出概率分布\n",
        "\n",
        "我们上面定义的函数$f$输入是鸢尾花的各项特征$\\mathbf{x}$，输出是一个连续的数值，代表花的品种。\n",
        "\n",
        "我们评量$f$的好坏时，计算的是预测数值$f(\\mathbf{x})$与真实品种$\\mathbf{y}$之间的均方误差。\n",
        "\n",
        "然而，这种做法对不同的类别而言不公平。\n",
        "\n",
        "例如，当预测类别$f(\\mathbf{x})=0$时，如果真实类别为$\\mathbf{y}=1$，则损失为$1$，但如果真实类别为$2$，则损失为2。\n",
        "\n",
        "同样是类别预测错误，真实类别为$2$时被认定为犯了更严重的错误，这对于类别$1$来说不公平。\n",
        "\n",
        "因此，在分类问题中，我们通常不直接输出代表类别的值，而是为每一个类别输出一个概率，形成一个**多分类概率分布（Categorical Distribution）**。\n",
        "\n",
        "因此，对于一条输入数据$\\mathbf{x}$，我们的函数定义应该变为：\n",
        "\n",
        "$$\n",
        "\\left[\\begin{aligned}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3\n",
        "\\end{aligned}\n",
        "\\right] = \\mathbf{f}(\\mathbf{x})=W^T\\mathbf{x}+\\mathbf{b}=\\left[\\begin{aligned}\n",
        "w_{11}~w_{12}~w_{13}~w_{14} \\\\\n",
        "w_{21}~w_{22}~w_{13}~w_{24} \\\\\n",
        "w_{31}~w_{32}~w_{13}~w_{34}\n",
        "\\end{aligned}\\right]\\cdot\\left[\\begin{aligned}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "x_4\n",
        "\\end{aligned}\n",
        "\\right]+\\left[\\begin{aligned}\n",
        "b_1 \\\\\n",
        "b_2 \\\\\n",
        "b_3\n",
        "\\end{aligned}\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "我们希望$y_1,y_2,y_3$分别代表花属于3种品种的概率，因此需要保证它们之和为$1$，因此我们再加入softmax函数：\n",
        "\n",
        "$$\n",
        "\\mathbf{f}(\\mathbf{x})=\\text{softmax}(W^T\\mathbf{x}+\\mathbf{b})\n",
        "$$\n",
        "\n",
        "这一函数的代码实现如下："
      ],
      "metadata": {
        "id": "4iOQJdO1sdti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class F4(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.W = nn.Parameter(torch.tensor([\n",
        "      [0.1,0.2,0.3,0.4],\n",
        "      [0.2,0.3,0.4,0.1],\n",
        "      [0.3,0.4,0.1,0.2],\n",
        "    ]))\n",
        "    self.b = nn.Parameter(torch.tensor([0.0,0.1,0.2]))\n",
        "    self.softmax = nn.Softmax(-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.softmax((self.W @ x.T).T + self.b)\n",
        "\n",
        "\n",
        "# 初始化函数\n",
        "f4 = F4()\n",
        "# 调用函数（把前2条数据攒成batch代入函数计算）\n",
        "y_dist = f4(\n",
        "  torch.tensor([\n",
        "    [5.1, 3.5, 1.4, 0.2],\n",
        "    [4.9, 3.0, 1.4, 0.2],\n",
        "  ])\n",
        ")\n",
        "print(y_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqNXAfhzr97P",
        "outputId": "3c554186-5990-4364-c3a5-da739fa1498f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1139, 0.3222, 0.5640],\n",
            "        [0.1259, 0.3321, 0.5420]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "需要注意，代码实现与公式的描述有些差异，但是是等价的：\n",
        "\n",
        "- 代码中的`self.W`其实是公式中的$W^T$，因此不再需要对`self.w`进行转置\n",
        "- 代码中的`x`是行向量，公式中的$\\mathbf{x}$是列向量，因此将`x`转置为`x.T`\n",
        "- 公式中的$W^T\\mathbf{x}$即为代码中的`self.w @ x.T`\n",
        "- 代码中的`b`是行向量，公式中的$\\mathbf{b}$是列向量，按道理应该对`b`进行转置，再与$W^T\\mathbf{x}$相加；但是这里`b`是一维的tensor（一维数组），无法转置，因此我们直接对`self.w @ x.T`再做一次转置成为`(self.w @ x.T).T`，再与`b`相加。\n",
        "- 代码中的输出是行向量，公式中的输出是列向量\n",
        "\n",
        "可以看到，我们给函数传入了一个大小为2的batch，其输出如下：\n",
        "\n",
        "- 第1条数据：11.39%概率为第0类品种，32.22%概率为第1类品种，56.40%概率为第2类品种\n",
        "- 第2条数据：12.59%概率为第0类品种，33.21%概率为第1类品种，54.20%概率为第2类品种\n",
        "\n",
        "这里，我们用到了一个$3\\times4$的矩阵作为参数$W^T$，以及一个3维的向量作为$b$，并把它们的初始值都硬编码在了`__init__`中。\n",
        "\n",
        "实际上，我们可以让它的初始值为随机值："
      ],
      "metadata": {
        "id": "SbHUTFovvz52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.random.manual_seed(42)  # 固定随机种子以便复现\n",
        "\n",
        "class F5(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.W = nn.Parameter(torch.randn(3, 4))  # 3x4的矩阵\n",
        "    self.b = nn.Parameter(torch.rand(3))  # 3维的向量\n",
        "    self.softmax = nn.Softmax(-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.softmax((self.W @ x.T).T + self.b)\n",
        "\n",
        "\n",
        "# 初始化函数\n",
        "f5 = F5()\n",
        "# 调用函数（把前2条数据攒成batch代入函数计算）\n",
        "y_dist = f5(\n",
        "  torch.tensor([\n",
        "    [5.1, 3.5, 1.4, 0.2],\n",
        "    [4.9, 3.0, 1.4, 0.2],\n",
        "  ])\n",
        ")\n",
        "print(y_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIIJmnt9yNpP",
        "outputId": "02f76c85-dcc9-4b99-e0fb-18e572bb633f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2869e-01, 3.9238e-04, 8.7092e-01],\n",
            "        [1.3959e-01, 6.6718e-04, 8.5974e-01]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里，`W`和`b`的目的是构建一个形如$\\mathbf{f}(X)=W^TX+b$的线性函数，该线性函数可以将4维的输入数据$[x_1,x_2,x_3,x_4]$映射为三维的品种概率分布$[y_1,y_2,y_3]$.\n",
        "\n",
        "在pytorch中有一个更简单的模块可以实现这一功能，即`nn.Linear`:"
      ],
      "metadata": {
        "id": "xFSymBy2zQu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.random.manual_seed(42)  # 固定随机种子以便复现\n",
        "\n",
        "class F6(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4, 3) # 输入为4维，输出为3维\n",
        "    self.softmax = nn.Softmax(-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.softmax(self.linear(x))\n",
        "\n",
        "\n",
        "# 初始化函数\n",
        "f6 = F6()\n",
        "# 调用函数（把前3条数据攒成batch代入函数计算）\n",
        "X = torch.tensor([\n",
        "  [5.1, 3.5, 1.4, 0.2],\n",
        "  [4.9, 3.0, 1.4, 0.2],\n",
        "])\n",
        "y_dist = f6(X)\n",
        "print(y_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HVto0I0y9qw",
        "outputId": "1d654291-acbb-4213-a90b-26ef725bee8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8541, 0.0139, 0.1320],\n",
            "        [0.8020, 0.0168, 0.1811]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.Linear`模块中包含了参数W和b，如下："
      ],
      "metadata": {
        "id": "OFj-0PPh3tIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f6.linear.weight)  # W\n",
        "print(f6.linear.bias)  # b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnPw9Clk3o7O",
        "outputId": "7bfea9fc-9022-4215-e0e6-0adc1695c1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3823,  0.4150, -0.1171,  0.4593],\n",
            "        [-0.1096,  0.1009, -0.2434,  0.2936],\n",
            "        [ 0.4408, -0.3668,  0.4346,  0.0936]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.3694, 0.0677, 0.2411], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "将数据`X`直接丢给`nn.Linear`等价于进行`WX+b`的运算:"
      ],
      "metadata": {
        "id": "lmlacCUG4PKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f6.linear(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93-elCvl4ANo",
        "outputId": "f72d8f37-6c61-4ba8-f01b-0ae3275f0c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.6994, -0.4199,  1.8323],\n",
              "        [ 3.4154, -0.4485,  1.9276]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(f6.linear.weight @ X.T).T + f6.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUfeCT8w4g3o",
        "outputId": "5af3fc68-015c-41a7-cf88-e60083082129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.6994, -0.4199,  1.8323],\n",
              "        [ 3.4154, -0.4485,  1.9276]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 最大化真实标签的概率\n",
        "\n",
        "上述函数输出了长度为3的向量，其中每个值表示鸢尾花属于每个类别的概率。\n",
        "\n",
        "我们需要最大化真实类别的概率。\n",
        "\n",
        "假设模型对于一个batch中4条输入所输出的概率分布为：\n"
      ],
      "metadata": {
        "id": "C6Coykqb_M4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_y_dist = torch.tensor([\n",
        "    [0.1, 0.2, 0.7],\n",
        "    [0.8, 0.1, 0.1],\n",
        "    [0.6, 0.2, 0.2],\n",
        "    [0.2, 0.7, 0.1]\n",
        "])"
      ],
      "metadata": {
        "id": "9_NX5Jx-be7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "假设4条输入对应的真实标签为："
      ],
      "metadata": {
        "id": "d4CxxOSwhZBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_y_true = torch.tensor([2, 0, 2, 1])"
      ],
      "metadata": {
        "id": "vTK7kiUIhVzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以批量地使用真实标签作为索引，取出真实标签的预测概率："
      ],
      "metadata": {
        "id": "_lE4bsy4hooD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_probs = mock_y_dist.gather(dim=1, index=mock_y_true[..., None])"
      ],
      "metadata": {
        "id": "eFYN6VUJhnWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里，`gather`操作用`mock_y_true`中的每个整数作为索引，提取出`mock_y_dist`中每一行对应位置的值："
      ],
      "metadata": {
        "id": "l_vAPpkqjDls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUfdW6S7iIif",
        "outputId": "1079081e-404f-4311-a3ca-7837d18cb5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7000],\n",
              "        [0.8000],\n",
              "        [0.2000],\n",
              "        [0.7000]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们将损失定义为所有`probs`的负对数的平均值："
      ],
      "metadata": {
        "id": "jeecoieeiXtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_loss = -mock_probs.log().mean()"
      ],
      "metadata": {
        "id": "gSjhaIZZiNz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mock_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLBPBo28j2oi",
        "outputId": "fa5df619-77af-4df9-f28d-f0f31fa6ac95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6365)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "损失越小，代表真实标签概率的负对数越小，代表真实标签的概率越大，从而代表模型对于真实标签预测的质量越好。\n",
        "\n",
        "将上述mock的过程定义为一个批量计算分类损失的函数："
      ],
      "metadata": {
        "id": "SRG3AQ5kkAfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_dist, y_true):\n",
        "  probs = y_dist.gather(dim=1, index=y_true[..., None])\n",
        "  return -probs.log().mean()"
      ],
      "metadata": {
        "id": "aWkB0oSMj3cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接下来开始训练："
      ],
      "metadata": {
        "id": "3tpViaJrkncY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = F6()\n",
        "optimizer = AdamW(f.parameters(), lr=0.1)\n",
        "num_epochs = 100\n",
        "for i_epoch in range(num_epochs):\n",
        "  # 前向传播\n",
        "  loss_list = []\n",
        "  for i in range(0, len(data_train), 4):\n",
        "    x = torch.tensor(np.array(data_train.iloc[i:i+4, :-1]), dtype=torch.float32)\n",
        "    y = torch.tensor(np.array(data_train.iloc[i:i+4, -1]), dtype=torch.long)\n",
        "    y_dist = f(x)\n",
        "    loss = cross_entropy_loss(y_dist, y)\n",
        "    loss_list.append(loss)\n",
        "  total_loss = sum(loss_list)\n",
        "  print(\"Total loss:\", total_loss.item())\n",
        "\n",
        "  # 反向传播\n",
        "  optimizer.zero_grad()  # 每次backward之前要先清空上次累积在后台的梯度\n",
        "  total_loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QXJhRtqkb2_",
        "outputId": "b9456d4f-31c1-4c50-9139-0bd8ae72034d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss: 42.622169494628906\n",
            "Total loss: 40.01057815551758\n",
            "Total loss: 45.771907806396484\n",
            "Total loss: 39.62301254272461\n",
            "Total loss: 30.42124366760254\n",
            "Total loss: 27.673301696777344\n",
            "Total loss: 26.51082992553711\n",
            "Total loss: 26.32590675354004\n",
            "Total loss: 25.836532592773438\n",
            "Total loss: 23.69374656677246\n",
            "Total loss: 21.142059326171875\n",
            "Total loss: 19.087554931640625\n",
            "Total loss: 18.144611358642578\n",
            "Total loss: 18.369930267333984\n",
            "Total loss: 18.445894241333008\n",
            "Total loss: 17.724994659423828\n",
            "Total loss: 17.006301879882812\n",
            "Total loss: 16.62527084350586\n",
            "Total loss: 16.06058692932129\n",
            "Total loss: 15.18472957611084\n",
            "Total loss: 14.506752014160156\n",
            "Total loss: 14.268475532531738\n",
            "Total loss: 14.059664726257324\n",
            "Total loss: 13.662631034851074\n",
            "Total loss: 13.374229431152344\n",
            "Total loss: 13.30797290802002\n",
            "Total loss: 13.185258865356445\n",
            "Total loss: 12.869413375854492\n",
            "Total loss: 12.551698684692383\n",
            "Total loss: 12.360967636108398\n",
            "Total loss: 12.149430274963379\n",
            "Total loss: 11.829717636108398\n",
            "Total loss: 11.551239013671875\n",
            "Total loss: 11.39216136932373\n",
            "Total loss: 11.23625659942627\n",
            "Total loss: 11.024679183959961\n",
            "Total loss: 10.847698211669922\n",
            "Total loss: 10.743281364440918\n",
            "Total loss: 10.622153282165527\n",
            "Total loss: 10.451108932495117\n",
            "Total loss: 10.300460815429688\n",
            "Total loss: 10.185643196105957\n",
            "Total loss: 10.048529624938965\n",
            "Total loss: 9.883220672607422\n",
            "Total loss: 9.740707397460938\n",
            "Total loss: 9.625947952270508\n",
            "Total loss: 9.499959945678711\n",
            "Total loss: 9.365974426269531\n",
            "Total loss: 9.256402969360352\n",
            "Total loss: 9.164204597473145\n",
            "Total loss: 9.062378883361816\n",
            "Total loss: 8.956531524658203\n",
            "Total loss: 8.865190505981445\n",
            "Total loss: 8.779354095458984\n",
            "Total loss: 8.683196067810059\n",
            "Total loss: 8.585470199584961\n",
            "Total loss: 8.498174667358398\n",
            "Total loss: 8.413763999938965\n",
            "Total loss: 8.324787139892578\n",
            "Total loss: 8.239302635192871\n",
            "Total loss: 8.16308307647705\n",
            "Total loss: 8.088897705078125\n",
            "Total loss: 8.012540817260742\n",
            "Total loss: 7.939671993255615\n",
            "Total loss: 7.871959686279297\n",
            "Total loss: 7.803737640380859\n",
            "Total loss: 7.7337422370910645\n",
            "Total loss: 7.666344165802002\n",
            "Total loss: 7.601934432983398\n",
            "Total loss: 7.537067413330078\n",
            "Total loss: 7.472221374511719\n",
            "Total loss: 7.4104204177856445\n",
            "Total loss: 7.351061820983887\n",
            "Total loss: 7.291848659515381\n",
            "Total loss: 7.23349666595459\n",
            "Total loss: 7.177541732788086\n",
            "Total loss: 7.122897624969482\n",
            "Total loss: 7.068177700042725\n",
            "Total loss: 7.014232635498047\n",
            "Total loss: 6.961899757385254\n",
            "Total loss: 6.9103102684021\n",
            "Total loss: 6.8589301109313965\n",
            "Total loss: 6.808598041534424\n",
            "Total loss: 6.759688377380371\n",
            "Total loss: 6.7115068435668945\n",
            "Total loss: 6.663862705230713\n",
            "Total loss: 6.617312908172607\n",
            "Total loss: 6.571854114532471\n",
            "Total loss: 6.52694845199585\n",
            "Total loss: 6.482583522796631\n",
            "Total loss: 6.43911075592041\n",
            "Total loss: 6.396420478820801\n",
            "Total loss: 6.3541998863220215\n",
            "Total loss: 6.312567710876465\n",
            "Total loss: 6.271749019622803\n",
            "Total loss: 6.23161506652832\n",
            "Total loss: 6.1919989585876465\n",
            "Total loss: 6.153022766113281\n",
            "Total loss: 6.114780902862549\n",
            "Total loss: 6.077128887176514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试模型性能："
      ],
      "metadata": {
        "id": "Hi9EF-sJluZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 前向传播\n",
        "loss_list = []\n",
        "y_preds = []\n",
        "y_trues = []\n",
        "for i in range(0, len(data_test), 4):\n",
        "  x = torch.tensor(np.array(data_test.iloc[i:i+4, :-1]), dtype=torch.float32)\n",
        "  y = torch.tensor(np.array(data_test.iloc[i:i+4, -1]), dtype=torch.long)\n",
        "  y_dist = f(x)\n",
        "  y_pred = y_dist.argmax(dim=1)  # 取概率最大的类别作为预测值\n",
        "  y_preds.extend(y_pred.tolist())\n",
        "  y_trues.extend(y.tolist())\n",
        "  loss = cross_entropy_loss(y_dist, y)\n",
        "  loss_list.append(loss)\n",
        "avg_loss = sum(loss_list) / len(loss_list)\n",
        "print(\"Average loss:\", avg_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh8kc8qek26R",
        "outputId": "5e88716f-69ad-4640-b2fd-ed3d3e7c086f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: tensor(0.1600, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (np.array(y_preds) == np.array(y_trues)).mean()\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew7cAeh5mItH",
        "outputId": "68dc48f4-5546-4d31-acbd-213470893cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bd_FsLTzmaMp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}