{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer难点理解与实现\n",
    "## 1 word embedding\n",
    "## 2 position embedding\n",
    "## 3 encoder self-attention mask\n",
    "## 4 intra-attention mask\n",
    "## 5 decoder self-attention mask\n",
    "## 6 multi-head self-attention\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## seq2seq基础模块的分类\n",
    "\n",
    "![](./imgs/6_1.png)\n",
    "\n",
    "\n",
    "\n",
    "![](./imgs/6_2.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Transformer模型\n",
    "\n",
    "## Encoder\n",
    "1. input word embedding\n",
    "    - one-hot * embedding table = 稠密的连续向量\n",
    "2. position encoding\n",
    "    - Position Embedding随着残差网络的连接可以传递到更高的神经网络层中（位置信息一直存在）\n",
    "3. multi-head self-attention\n",
    "4. feed forward network\n",
    "\n",
    "![](./imgs/6_3.png)\n",
    "\n",
    "![](./imgs/6_4.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decoder\n",
    "\n",
    "![](./imgs/6_5.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. word embedding\n",
    "\n",
    "对一段文本的处理：\n",
    "1. 筛选出文本中所有单词\n",
    "2. 建立词表，对拆分出的单词建立索引\n",
    "3. 将文本转为索引列表\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 构建输入和输出"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# 设置种子数\n",
    "random_seed = int(time.time() * 2)\n",
    "\n",
    "# 固定种子程序\n",
    "def seed_it(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True #确定性固定\n",
    "    torch.backends.cudnn.benchmark = True #False会确定性地选择算法，会降低性能\n",
    "    torch.backends.cudnn.enabled = True  #增加运行效率，默认就是True\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_it(random_seed)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:00.837164495Z",
     "start_time": "2023-07-20T05:25:00.832990235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([2, 4], dtype=torch.int32), tensor([4, 3], dtype=torch.int32))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "以序列建模为例，构建序列，序列的字符以其在词表中的索引的形式表示\n",
    "\"\"\"\n",
    "\n",
    "batch_size=2\n",
    "\n",
    "# 序列的最大长度\n",
    "max_src_seq_len=5\n",
    "max_tgt_seq_len=5\n",
    "\n",
    "# 单词表大小（embedding中num_embeddings参数（单词的个数））\n",
    "max_num_src_words=8\n",
    "max_num_tgt_words=8\n",
    "\n",
    "# embedding中embedding_dim大小(模型的特征大小)\n",
    "model_dim=8\n",
    "\n",
    "\n",
    "# 生成长度为2和4的两个源句子\n",
    "src_len=torch.Tensor([2,4]).to(torch.int32)\n",
    "\n",
    "# 生成长度为4和3的两个目标句子\n",
    "tgt_len=torch.Tensor([4,3]).to(torch.int32)\n",
    "\n",
    "src_len,tgt_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:03.227432038Z",
     "start_time": "2023-07-20T05:25:03.222427544Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([7, 7, 0, 0, 0]), tensor([5, 3, 5, 2, 0])]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "详细步骤（运行时可略过）\n",
    "\"\"\"\n",
    "\n",
    "# 生成1到max_src_seq_len之间，长度为L的一维张量(单词索引构成的句子)\n",
    "src_seq=[\n",
    "       torch.randint(\n",
    "            low=1,\n",
    "            high=max_num_src_words,\n",
    "            size=(L,)) for L in src_len\n",
    "]\n",
    "# 此时的src_seq为list，内容是两个一维的张量(两个句子)\n",
    "src_seq  # [tensor([2, 7]), tensor([6, 5, 7, 4])]\n",
    "\n",
    "# 按照最大序列长度进行0填充(pad)\n",
    "for i in range(len(src_len)):\n",
    "    L=int(src_len[i])\n",
    "    src_seq[i]=F.pad(src_seq[i],(0,max_src_seq_len-L))\n",
    "# 此时的src_seq为list，内容是两个一维的张量(两个句子)\n",
    "src_seq # [tensor([2, 7, 0, 0, 0]), tensor([6, 5, 7, 4, 0])]\n",
    "\n",
    "# 将列表中的每个一维tensor转为二维tensor\n",
    "src_seq=torch.cat([torch.unsqueeze(src_seq[L],dim=0) for L in range(len(src_seq)) ])\n",
    "\n",
    "src_seq  # tensor([[7, 7, 0, 0, 0],\n",
    "         #         [5, 3, 5, 2, 0]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T15:57:12.433889587Z",
     "start_time": "2023-07-19T15:57:12.379229318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[5, 7, 0, 0],\n         [2, 5, 1, 5]]),\n tensor([[6, 6, 1, 1],\n         [6, 6, 7, 0]]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "合并上述操作\n",
    "- torch.randint: 生成指定范围的指定形状的整数\n",
    "- F.pad：默认填充0\n",
    "- torch.unsqueeze：在指定维度上扩展张量的维度\n",
    "- torch.cat：拼接两个张量\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Step1: 单词索引构成源句子和目标句子，构建batch，并且做了padding，默认值为0\n",
    "\"\"\"\n",
    "src_seq = torch.cat(\n",
    "    [torch.unsqueeze(F.pad(torch.randint(1,max_num_src_words,(L,)), (0,max(src_len)-L)),0 ) for L in src_len]\n",
    ")\n",
    "\n",
    "tgt_seq = torch.cat(\n",
    "    [torch.unsqueeze(F.pad(torch.randint(1,max_num_tgt_words,(L,)), (0,max(tgt_len)-L)),0 ) for L in tgt_len]\n",
    ")\n",
    "\n",
    "src_seq,tgt_seq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:06.842994763Z",
     "start_time": "2023-07-20T05:25:06.839367602Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 构造 word embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(9, 8)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_embedding_table=nn.Embedding(max_num_src_words+1,model_dim)\n",
    "tgt_embedding_table=nn.Embedding(max_num_tgt_words+1,model_dim)\n",
    "\n",
    "src_embedding_table  # 从table中获取单词的embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:10.299347701Z",
     "start_time": "2023-07-20T05:25:10.296026969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-1.8971, -0.5292, -0.2683, -0.4533, -1.3878, -0.3119,  1.5240,  0.6145],\n        [-0.8193, -2.2878,  0.9385,  0.5366,  0.3396,  0.2181, -0.1508, -0.4788],\n        [-0.7597,  0.9148, -0.5178,  1.4354, -0.1013,  1.5633, -0.4738,  0.4313],\n        [ 1.5991,  0.5838,  0.1552, -1.9887,  1.0617,  0.2108, -0.4492, -1.0874],\n        [ 2.3204,  0.4021,  1.9740,  1.1001,  0.7008, -0.9758, -0.5534,  0.4126],\n        [-0.4560,  1.1002, -0.5133,  2.2987,  0.8974, -0.2775,  0.5889,  1.2542],\n        [ 0.4470, -0.8439, -1.2878, -0.2874,  0.3921, -1.0862, -0.1129,  1.1329],\n        [ 0.1421, -0.2498,  0.2293,  1.1480, -0.8974,  2.3922,  0.2216,  2.2292],\n        [ 0.4339, -0.3328, -0.2964,  1.2370,  1.1829, -1.3129, -1.3691,  0.7486]],\n       requires_grad=True)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "每一行代表embedding向量\n",
    "- 其中第0行为pad\n",
    "- 其余行分配给单词\n",
    "\"\"\"\n",
    "src_embedding_table.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:11.826879698Z",
     "start_time": "2023-07-20T05:25:11.823429303Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 调用forward方法，获取句子的embedding vector\n",
    "src_embedding=src_embedding_table(src_seq)\n",
    "tgt_embedding=tgt_embedding_table(tgt_seq)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:13.413722179Z",
     "start_time": "2023-07-20T05:25:13.410127900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[5, 7, 0, 0],\n         [2, 5, 1, 5]]),\n tensor([[[-0.4560,  1.1002, -0.5133,  2.2987,  0.8974, -0.2775,  0.5889,\n            1.2542],\n          [ 0.1421, -0.2498,  0.2293,  1.1480, -0.8974,  2.3922,  0.2216,\n            2.2292],\n          [-1.8971, -0.5292, -0.2683, -0.4533, -1.3878, -0.3119,  1.5240,\n            0.6145],\n          [-1.8971, -0.5292, -0.2683, -0.4533, -1.3878, -0.3119,  1.5240,\n            0.6145]],\n \n         [[-0.7597,  0.9148, -0.5178,  1.4354, -0.1013,  1.5633, -0.4738,\n            0.4313],\n          [-0.4560,  1.1002, -0.5133,  2.2987,  0.8974, -0.2775,  0.5889,\n            1.2542],\n          [-0.8193, -2.2878,  0.9385,  0.5366,  0.3396,  0.2181, -0.1508,\n           -0.4788],\n          [-0.4560,  1.1002, -0.5133,  2.2987,  0.8974, -0.2775,  0.5889,\n            1.2542]]], grad_fn=<EmbeddingBackward0>),\n torch.Size([2, 4, 8]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "根据每个句子中每个单词的索引值在上面的`src_embedding_table.weight`中找到相应的行数，即可作为句子的embedding vector\n",
    "\"\"\"\n",
    "src_seq,src_embedding,src_embedding.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:14.920912847Z",
     "start_time": "2023-07-20T05:25:14.903057442Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. position embedding\n",
    "\n",
    "attention is all you need中position embedding的理由：\n",
    "1. 泛化能力强，即使在测试集中出现未知的序列长度，亦可根据已有的序列长度，求一个线性方程，然后求出序列\n",
    "2. 具有对称性和唯一性，每个位置的embedding是确定的\n",
    "\n",
    "![](./imgs/6_6.png)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0],\n         [1],\n         [2],\n         [3],\n         [4]]),\n tensor([[   1.,   10.,  100., 1000.]]))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义序列编码的最大长度(总共的位置数目)\n",
    "max_position_len=5\n",
    "\n",
    "# 构造position embedding\n",
    "pos_mat=torch.arange(max_position_len).reshape((-1,1))\n",
    "i_mat=torch.pow(10000,torch.arange(0,8,2).reshape((1,-1))/model_dim)\n",
    "\n",
    "pos_mat,i_mat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:18.210274179Z",
     "start_time": "2023-07-20T05:25:18.205254302Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n          1.0000e+00,  0.0000e+00,  1.0000e+00],\n        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n          9.9995e-01,  1.0000e-03,  1.0000e+00],\n        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n          9.9980e-01,  2.0000e-03,  1.0000e+00],\n        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n          9.9955e-01,  3.0000e-03,  1.0000e+00],\n        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n          9.9920e-01,  4.0000e-03,  9.9999e-01]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_embedding_table=torch.zeros(max_position_len,model_dim)\n",
    "pe_embedding_table[:,0::2]=torch.sin(pos_mat/i_mat)\n",
    "pe_embedding_table[:,1::2]=torch.cos(pos_mat/i_mat)\n",
    "pe_embedding_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:19.531171760Z",
     "start_time": "2023-07-20T05:25:19.527921616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n          1.0000e+00,  0.0000e+00,  1.0000e+00],\n        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n          9.9995e-01,  1.0000e-03,  1.0000e+00],\n        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n          9.9980e-01,  2.0000e-03,  1.0000e+00],\n        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n          9.9955e-01,  3.0000e-03,  1.0000e+00],\n        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n          9.9920e-01,  4.0000e-03,  9.9999e-01]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将构造的table当作embedding的权值传入\n",
    "pe_embedding=nn.Embedding(max_position_len,model_dim)\n",
    "pe_embedding.weight=nn.Parameter(pe_embedding_table,requires_grad=False)\n",
    "pe_embedding.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:20.857678244Z",
     "start_time": "2023-07-20T05:25:20.855060990Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           1.0000e+00,  0.0000e+00,  1.0000e+00],\n         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n           9.9995e-01,  1.0000e-03,  1.0000e+00],\n         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n           9.9980e-01,  2.0000e-03,  1.0000e+00],\n         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n\n        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           1.0000e+00,  0.0000e+00,  1.0000e+00],\n         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n           9.9995e-01,  1.0000e-03,  1.0000e+00],\n         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n           9.9980e-01,  2.0000e-03,  1.0000e+00],\n         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n           9.9955e-01,  3.0000e-03,  1.0000e+00]]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_pos=torch.cat([torch.unsqueeze(torch.arange(max(src_len)),0) for _ in src_seq]).to(torch.int32)\n",
    "tgt_pos=torch.cat([torch.unsqueeze(torch.arange(max(src_len)),0) for _ in tgt_seq]).to(torch.int32)\n",
    "# 向pe_embedding中传入位置索引\n",
    "src_pe_embedding=pe_embedding(src_pos)\n",
    "tgt_pe_embedding=pe_embedding(tgt_pos)\n",
    "\n",
    "# 借助nn.embedding API，通过位置索引就可以得到位置embedding\n",
    "src_pe_embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:22.811811116Z",
     "start_time": "2023-07-20T05:25:22.805721353Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. encoder self-attention mask\n",
    "\n",
    "### 3.1 softmax演示（scaled的重要性）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.0403,  0.8497, -0.2018,  1.6455, -0.9434])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "softmax演示\n",
    "\"\"\"\n",
    "\n",
    "alpha1=0.1\n",
    "alpha2=10\n",
    "\n",
    "# 将该分数看到Query与key的相似度(Q*K结果)\n",
    "# 即一个单词与整个序列的相似度结果\n",
    "score=torch.randn(5)\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T02:11:31.358535756Z",
     "start_time": "2023-07-20T02:11:31.314287931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.1945, 0.2109, 0.1899, 0.2284, 0.1763])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到query与序列中每个单词的相似度\n",
    "# prob越大，相似度越大\n",
    "\n",
    "# 概率差别小\n",
    "prob1=F.softmax(score*alpha1,-1)\n",
    "prob1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T02:11:32.740794699Z",
     "start_time": "2023-07-20T02:11:32.737939542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0677e-07, 3.4968e-04, 9.4866e-09, 9.9965e-01, 5.7049e-12])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 概率差别大\n",
    "prob2=F.softmax(score*alpha2,-1)\n",
    "prob2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T02:11:34.005110342Z",
     "start_time": "2023-07-20T02:11:34.002252006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29636/2182463120.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(score)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.1567, -0.0410, -0.0369, -0.0444, -0.0343],\n        [-0.0410,  0.1664, -0.0400, -0.0482, -0.0372],\n        [-0.0369, -0.0400,  0.1538, -0.0434, -0.0335],\n        [-0.0444, -0.0482, -0.0434,  0.1762, -0.0403],\n        [-0.0343, -0.0372, -0.0335, -0.0403,  0.1452]])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_func(score):\n",
    "    return F.softmax(score)\n",
    "jaco_mat1=torch.autograd.functional.jacobian(softmax_func,score*alpha1)\n",
    "jaco_mat1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T02:15:49.270480481Z",
     "start_time": "2023-07-20T02:15:49.267454703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29636/2182463120.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(score)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 1.0677e-07, -3.7334e-11, -1.0128e-15, -1.0673e-07, -6.0909e-19],\n        [-3.7334e-11,  3.4956e-04, -3.3173e-12, -3.4956e-04, -1.9949e-15],\n        [-1.0128e-15, -3.3173e-12,  9.4866e-09, -9.4832e-09, -5.4120e-20],\n        [-1.0673e-07, -3.4956e-04, -9.4832e-09,  3.4964e-04, -5.7029e-12],\n        [-6.0909e-19, -1.9949e-15, -5.4120e-20, -5.7029e-12,  5.7049e-12]])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaco_mat2=torch.autograd.functional.jacobian(softmax_func,score*alpha2)\n",
    "jaco_mat2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T02:15:53.696680820Z",
     "start_time": "2023-07-20T02:15:53.693572458Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Scaled Dot-Product Attention"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.],\n         [1.],\n         [0.],\n         [0.]],\n\n        [[1.],\n         [1.],\n         [1.],\n         [1.]]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "构造encoder的self-attention mask\n",
    "\n",
    "mask的shape:[batch_size,max_src_len,max_src_len],值为1或-inf\n",
    "\"\"\"\n",
    "\n",
    "# 有效编码器位置矩阵\n",
    "valid_encoder_pos=torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max(src_len)-L)) ,0) for L in src_len]),2)\n",
    "valid_encoder_pos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:29.756121288Z",
     "start_time": "2023-07-20T05:25:29.710799948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 4, 1])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2:batch_size\n",
    "4:每个句子pad之后的最大长度\n",
    "\"\"\"\n",
    "valid_encoder_pos.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:31.481304145Z",
     "start_time": "2023-07-20T05:25:31.479641353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[1., 1., 0., 0.],\n          [1., 1., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n \n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]]),\n torch.Size([2, 4, 4]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bmm:三维矩阵相乘(element-wise product)\n",
    "\"\"\"\n",
    "valid_encoder_pos_matrix=torch.bmm(valid_encoder_pos,valid_encoder_pos.transpose(1,2))\n",
    "valid_encoder_pos_matrix,valid_encoder_pos_matrix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:33.107810753Z",
     "start_time": "2023-07-20T05:25:33.103513063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0., 0., 1., 1.],\n         [0., 0., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_encoder_pos_matrix=1-valid_encoder_pos_matrix\n",
    "invalid_encoder_pos_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:34.972271148Z",
     "start_time": "2023-07-20T05:25:34.967803537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[False, False,  True,  True],\n          [False, False,  True,  True],\n          [ True,  True,  True,  True],\n          [ True,  True,  True,  True]],\n \n         [[False, False, False, False],\n          [False, False, False, False],\n          [False, False, False, False],\n          [False, False, False, False]]]),\n torch.Size([2, 4, 4]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将位置编码矩阵变为bool型\n",
    "# Ture:该位置需要被mask\n",
    "mask_encoder_self_attention=invalid_encoder_pos_matrix.to(torch.bool)\n",
    "mask_encoder_self_attention,mask_encoder_self_attention.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:37.112391469Z",
     "start_time": "2023-07-20T05:25:37.109712003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 1.6365, -1.5191, -0.2236,  0.3235],\n          [-0.0399,  0.4800,  1.8378,  1.0547],\n          [ 0.5063,  1.3518, -0.8374, -1.6042],\n          [-1.1921, -0.2160,  0.1581,  0.7136]],\n \n         [[-1.8907,  0.3340, -1.6852,  1.1155],\n          [ 0.1832,  0.9547,  1.3048, -1.5454],\n          [ 0.6335,  1.0391, -0.6470,  1.2854],\n          [ 0.4862,  0.5130,  1.7316, -0.2617]]]),\n torch.Size([2, 4, 4]))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=torch.randn(batch_size,max(src_len),max(src_len))\n",
    "score,score.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:38.929822189Z",
     "start_time": "2023-07-20T05:25:38.926605837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 1.6365e+00, -1.5191e+00, -1.0000e+09, -1.0000e+09],\n         [-3.9859e-02,  4.7999e-01, -1.0000e+09, -1.0000e+09],\n         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n\n        [[-1.8907e+00,  3.3396e-01, -1.6852e+00,  1.1155e+00],\n         [ 1.8322e-01,  9.5474e-01,  1.3048e+00, -1.5454e+00],\n         [ 6.3351e-01,  1.0391e+00, -6.4700e-01,  1.2854e+00],\n         [ 4.8617e-01,  5.1296e-01,  1.7316e+00, -2.6172e-01]]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masked_score=score.masked_fill(mask_encoder_self_attention,-np.inf)\n",
    "masked_score=score.masked_fill(mask_encoder_self_attention,-1e9)\n",
    "masked_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:40.394532439Z",
     "start_time": "2023-07-20T05:25:40.390694863Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.9591, 0.0409, 0.0000, 0.0000],\n         [0.3729, 0.6271, 0.0000, 0.0000],\n         [0.2500, 0.2500, 0.2500, 0.2500],\n         [0.2500, 0.2500, 0.2500, 0.2500]],\n\n        [[0.0316, 0.2919, 0.0388, 0.6378],\n         [0.1560, 0.3374, 0.4789, 0.0277],\n         [0.2129, 0.3194, 0.0592, 0.4086],\n         [0.1674, 0.1719, 0.5815, 0.0792]]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob=F.softmax(masked_score,-1)\n",
    "prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:42.209888214Z",
     "start_time": "2023-07-20T05:25:42.207611833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. intra-attention mask\n",
    "\n",
    "Q @ K^{T} shape: [batch_size,tgt_seq_len,src_seq_len]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.],\n         [1.],\n         [0.],\n         [0.]],\n\n        [[1.],\n         [1.],\n         [1.],\n         [1.]]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_encoder_pos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:43.922340709Z",
     "start_time": "2023-07-20T05:25:43.919516125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[1.],\n          [1.],\n          [1.],\n          [1.]],\n \n         [[1.],\n          [1.],\n          [1.],\n          [0.]]]),\n torch.Size([2, 4, 1]))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有效编码器位置矩阵\n",
    "valid_decoder_pos=torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max(tgt_len)-L)) ,0) for L in tgt_len]),2)\n",
    "valid_decoder_pos,valid_decoder_pos.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:45.371012764Z",
     "start_time": "2023-07-20T05:25:45.368294225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1., 1., 0., 0.],\n         [1., 1., 0., 0.],\n         [1., 1., 0., 0.],\n         [1., 1., 0., 0.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [0., 0., 0., 0.]]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_cross_pos_matrix=torch.bmm(valid_decoder_pos,valid_encoder_pos.transpose(1,2))\n",
    "valid_cross_pos_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:47.122855664Z",
     "start_time": "2023-07-20T05:25:47.119787219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[False, False,  True,  True],\n         [False, False,  True,  True],\n         [False, False,  True,  True],\n         [False, False,  True,  True]],\n\n        [[False, False, False, False],\n         [False, False, False, False],\n         [False, False, False, False],\n         [ True,  True,  True,  True]]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_cross_pos_matrix=1-valid_cross_pos_matrix\n",
    "mask_cross_attention=invalid_cross_pos_matrix.to(torch.bool)\n",
    "mask_cross_attention"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:48.483276112Z",
     "start_time": "2023-07-20T05:25:48.479658703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. decoder self-attention mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[1., 0., 0., 0.],\n         [1., 1., 0., 0.],\n         [1., 1., 1., 0.],\n         [1., 1., 1., 1.]]),\n tensor([[1., 0., 0.],\n         [1., 1., 0.],\n         [1., 1., 1.]])]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造下三角矩阵\n",
    "tri_matrix=[torch.tril(torch.ones((L,L))) for L in tgt_len]\n",
    "tri_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:25:56.903283743Z",
     "start_time": "2023-07-20T05:25:56.895038968Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[1., 0., 0., 0.],\n          [1., 1., 0., 0.],\n          [1., 1., 1., 0.],\n          [1., 1., 1., 1.]],\n \n         [[1., 0., 0., 0.],\n          [1., 1., 0., 0.],\n          [1., 1., 1., 0.],\n          [0., 0., 0., 0.]]]),\n torch.Size([2, 4, 4]))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_decoder_tri_matrix=torch.cat([ torch.unsqueeze(F.pad(torch.tril(torch.ones((L,L))), (0,max(tgt_len)-L,0,max(tgt_len)-L) ),0) for L in tgt_len ])\n",
    "valid_decoder_tri_matrix,valid_decoder_tri_matrix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:45:30.140052624Z",
     "start_time": "2023-07-20T05:45:30.088807903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[False,  True,  True,  True],\n         [False, False,  True,  True],\n         [False, False, False,  True],\n         [False, False, False, False]],\n\n        [[False,  True,  True,  True],\n         [False, False,  True,  True],\n         [False, False, False,  True],\n         [ True,  True,  True,  True]]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoder因果掩码\n",
    "invalid_decoder_tri_matrix=(1-valid_decoder_tri_matrix).to(torch.bool)\n",
    "invalid_decoder_tri_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:50:07.065983113Z",
     "start_time": "2023-07-20T05:50:07.062388881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n         [0.5944, 0.4056, 0.0000, 0.0000],\n         [0.0514, 0.8686, 0.0799, 0.0000],\n         [0.1175, 0.5565, 0.1232, 0.2028]],\n\n        [[1.0000, 0.0000, 0.0000, 0.0000],\n         [0.9241, 0.0759, 0.0000, 0.0000],\n         [0.3277, 0.1568, 0.5155, 0.0000],\n         [0.2500, 0.2500, 0.2500, 0.2500]]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=torch.randn(batch_size,max(tgt_len),max(tgt_len))\n",
    "masked_score=score.masked_fill(invalid_decoder_tri_matrix,-1e9)\n",
    "prob=F.softmax(masked_score,-1)\n",
    "# 注意力权重矩阵\n",
    "prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T05:52:04.024147287Z",
     "start_time": "2023-07-20T05:52:03.978306809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. scaled self-attention"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q,K,V,attn_mask):\n",
    "    # shape of Q,K,V:[batch_size*num_head, seq_len, model_dim/num_head]\n",
    "    score=torch.bmm(Q,K.transpose(-2,-1))/torch.sqrt(model_dim)\n",
    "    masked_score=score.masked_fill(attn_mask,-1e9)\n",
    "    prob=F.softmax(masked_score,-1)\n",
    "    context=torch.bmm(prob,V)\n",
    "    return context"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Masked loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-2.0492,  0.9944,  1.2019, -0.3054],\n         [ 1.7441,  1.2566, -0.0404,  0.4397],\n         [-1.4987, -1.8955, -0.8323, -0.1094]],\n\n        [[ 2.1624,  1.3874, -0.3114, -0.6915],\n         [ 0.3334, -0.1706,  1.1871,  0.3635],\n         [-0.5511,  1.4288,  1.2365,  0.2242]]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size=2,seqlen=3,vocab_size=4\n",
    "logits=torch.randn(2,3,4)\n",
    "logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T06:51:07.677729385Z",
     "start_time": "2023-07-20T06:51:07.612181363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[3, 1, 0],\n        [0, 3, 1]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=torch.randint(0,4,(2,3))\n",
    "label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T07:59:27.415954780Z",
     "start_time": "2023-07-20T07:59:27.355216093Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-2.0492,  1.7441, -1.4987],\n         [ 0.9944,  1.2566, -1.8955],\n         [ 1.2019, -0.0404, -0.8323],\n         [-0.3054,  0.4397, -0.1094]],\n\n        [[ 2.1624,  0.3334, -0.5511],\n         [ 1.3874, -0.1706,  1.4288],\n         [-0.3114,  1.1871,  1.2365],\n         [-0.6915,  0.3635,  0.2242]]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=logits.transpose(1,2)\n",
    "logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T07:59:48.593080185Z",
     "start_time": "2023-07-20T07:59:48.589251031Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.2362, 1.2070, 2.0323],\n        [0.4716, 1.5759, 0.8167]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits,label,reduction='none')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T08:00:19.013846946Z",
     "start_time": "2023-07-20T08:00:18.983537184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([1., 1.]), tensor([1., 1., 1.])]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_len=torch.tensor([2,3]).to(torch.int32)\n",
    "[torch.ones(L) for L in tgt_len]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T08:02:07.585490910Z",
     "start_time": "2023-07-20T08:02:07.522408128Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 0.],\n        [1., 1., 1.]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max(tgt_len)-L)),0) for L in tgt_len])\n",
    "mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T08:03:20.645382071Z",
     "start_time": "2023-07-20T08:03:20.575223789Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.2362, 1.2070, 0.0000],\n        [0.4716, 1.5759, 0.8167]])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits,label,reduction='none') * mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T08:03:41.706798596Z",
     "start_time": "2023-07-20T08:03:41.642641864Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[3, 1, 0],\n        [0, 3, 1]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T08:03:59.153944210Z",
     "start_time": "2023-07-20T08:03:59.151084033Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "label[0,2]=-100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T08:04:19.041987406Z",
     "start_time": "2023-07-20T08:04:19.038994338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.2362, 1.2070, 0.0000],\n        [0.4716, 1.5759, 0.8167]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits,label,reduction='none') * mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T08:04:31.215912614Z",
     "start_time": "2023-07-20T08:04:31.173256127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer模型总结\n",
    "## 模型结构\n",
    "![](./imgs/6_9.png)\n",
    "![](./imgs/6_10.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用类型\n",
    "![](./imgs/6_8.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特点\n",
    "![](./imgs/6_7.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
